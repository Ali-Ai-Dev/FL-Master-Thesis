% Chapter 5
\chapter{پیاده‌سازی و بررسی نتایج}

\section{مقدمه}
در این فصل به پیاده‌سازی شبکه‌های عصبی و تحلیل نتایج آن‌ها پرداخته می‌شود. ابتدا، دو مدل اصلی که در این ‎پژوهش استفاده شده‌اند، معرفی و پیاده‌سازی می‌شوند. جزئیات هر مدل، شامل ابعاد لایه‌ها، توابع فعال‌سازی و ساختار کلی آن‌ها توضیح داده شده است. 
سپس مجموعه داده‌ها معرفی شده و نتایج اجرای مدل‌ها با روش ‎\lr{SimFedSwap}‎ بررسی می‌گردد. در این بررسی، مقایسه‌هایی با دیگر روش‌های مرسوم از نظر تعداد تکرار و جابه‌جایی بر اساس روش حریصانه و حداقل شباهت انجام می‌شود.


%معرفی انواع مجموعه داده و مقایسه روش
%\lr{\texttt{\fontspec{Times New Roman} SimFedSwap}}
%با روش‌های پایه
%
%در این پژوهش از انواع مجموعه داده‌ها برای بررسی و ارزیابی روش مورد نظر استفاده شده است. این مجموعه داده‌ها هر یک ویژگی‌های منحصر به فردی دارند که به تحلیل‌های دقیق‌تر و جامع‌تر کمک می‌کنند. در ادامه، هر یک از این مجموعه داده‌ها به‌طور مفصل معرفی و توضیح داده خواهند شد تا اهمیت و کاربردهای آن‌ها مشخص گردد.




\section{پیاده‌سازی مدل‌های شبکه عصبی}
در این بخش، دو ساختار و مدل اصلی شبکه‌های عصبی، شامل شبکه عصبی پرسپترون چندلایه%
\LTRfootnote{MultiLayer Perceptron}
\lr{(MLP)}
و شبکه عصبی پیچشی%
\LTRfootnote{Convolutional Neural Network}
\lr{(CNN)}
مورد بررسی قرار خواهند گرفت.
این بررسی به منظور فراهم آوردن درکی جامع از نحوه عملکرد هر مدل، نقش آن‌ها در بررسی نتایج و مقایسه روش‌ها در پژوهش انجام خواهد شد. به عبارت دیگر استفاده از این مدل‌ها به تحلیل و ارزیابی دقیق‌تر نتایج کمک کرده و مقایسه‌ای جامع از روش‌های مختلف را ممکن می‌سازد.

\subsection{
	مدل
	\lr{\texttt{\fontspec{Times New Roman} MLP}}
}
در شبکه عصبی چندلایه، ابتدا لایه‌های شبکه عصبی در قالب یک ساختار ترتیبی%
\LTRfootnote{Sequential}
ایجاد می‌شوند. این ساختار ترتیب‌دار باعث می‌شود که لایه‌ها به‌صورت متوالی اجرا شوند و خروجی هر لایه به عنوان ورودی به لایه بعدی منتقل شود.

اولین لایه، یک لایه کاملاً متصل است که تعداد نورون‌های ورودی آن برابر با تعداد ویژگی‌های ورودی مدل به‌صورت مسطح‌شده و تعداد نورون‌های خروجی آن 256 است. این لایه تمام اتصالات ممکن بین نورون‌های ورودی و خروجی را دارد. پس از این لایه، یک تابع فعال‌سازی 
\lr{ReLU}
قرار دارد که وظیفه آن این است که تمامی مقادیر منفی خروجی را به صفر تبدیل کند و مقادیر مثبت را بدون تغییر نگه دارد.

لایه دوم، یک لایه کاملاً متصل دیگر است که 256 نورون ورودی و 128 نورون خروجی دارد. پس از این لایه نیز یک تابع فعال‌سازی
\lr{ReLU}
قرار دارد که مشابه تابع فعال‌ساز قبلی عمل می‌کند. سومین لایه نیز دقیقا مشابه لایه دوم است با این تفاوت که 128 نورون به عنوان ورودی و 64 نورون به عنوان خروجی دارد و در ادامه آن هم تابع فعال‌سازی
\lr{ReLU}
وجود دارد.

چهارمین و آخرین لایه، یک لایه کاملاً متصل است که 64 نورون ورودی و تعداد نورون‌های خروجی آن برابر با تعداد کلاس‌های موجود در مسئله طبقه‌بندی است. این لایه، خروجی‌های نهایی شبکه را تولید می‌کند که نشان‌دهنده میزان تعلق هر ورودی به هر یک از کلاس‌ها است.

در نهایت، یک لایه 
\lr{Softmax}
اضافه شده است که وظیفه آن تبدیل خروجی‌های نهایی شبکه به توزیع احتمالاتی است. این لایه کمک می‌کند تا بتوان احتمال تعلق هر ورودی به هر کلاس را به‌صورت عددی بین صفر و یک به دست آورد که جمع کل این احتمالات برای همه کلاس‌ها برابر با یک خواهد بود. این توزیع احتمالاتی برای انجام پیش‌بینی‌های نهایی مورد استفاده قرار می‌گیرد. در پایان می‌توانید ساختار این مدل را در شکل
\ref{mlp}
مشاهده نمایید.

\begin{figure}[t!]
	\centering
	\includegraphics[scale=0.7]{images/chap5/mlp.png}%
	\caption{
		ساختار مدل 
		\lr{MLP}.
	}
	\label{mlp}
	\centering
\end{figure}



\subsection{
	مدل
	\lr{\texttt{\fontspec{Times New Roman} CNN}}
}
در شبکه عصبی پیچشی، ابتدا یک بلوک ترتیبی شامل لایه‌های مختلف تعریف شده است. این لایه‌ها به ترتیب وظایف مختلفی در استخراج ویژگی‌ها و انجام طبقه‌بندی نهایی دارند.
اولین لایه، یک لایه پیچشی تعریف شده است که تعداد کانال‌های ورودی تصویر را به 32 کانال خروجی تبدیل می‌کند. این لایه از یک هسته ‎پیچشی با اندازه
3$\times$3
استفاده می‌کند. این لایه وظیفه دارد تا ویژگی‌های ابتدایی تصویر ورودی را استخراج کند. پس از این لایه، یک تابع فعال‌سازی 
\lr{ReLU}
قرار دارد که مقادیر منفی را به صفر تبدیل کرده و مقادیر مثبت را بدون تغییر نگه می‌دارد که این کار باعث ایجاد غیرخطی‌ شدن شبکه می‌شود.

سپس یک لایه تجمیع حداکثر%
\LTRfootnote{Max Pooling}
قرار دارد که اندازه فضای ویژگی‌های خروجی را کاهش می‌دهد و به کم کردن تعداد پارامترها و افزایش کارایی مدل کمک می‌کند. این لایه با انتخاب حداکثر مقدار در هر ناحیه کوچک
2$\times$2،
منجر به کاهش ابعاد تصاویر خواهد شد.

در ادامه، یک لایه پیچشی دیگر قرار دارد که تعداد کانال‌های خروجی را به 64 کانال افزایش می‌دهد. این لایه نیز از یک هسته پیچشی با اندازه
3$\times$3
استفاده می‌کند و وظیفه استخراج ویژگی‌های پیچیده‌تر را بر عهده دارد. پس از این لایه نیز یک تابع فعال‌سازی
\lr{ReLU}
قرار دارد که مشابه قبل عمل می‌کند.

سپس یک لایه تجمیع حداکثر دیگر قرار دارد که اندازه فضای ویژگی‌های خروجی را مجدداً کاهش می‌دهد. این لایه نیز با انتخاب حداکثر مقدار در هر ناحیه کوچک
2$\times$2،
به کاهش ابعاد تصاویر کمک می‌کند.

پس از این لایه‌ها، یک لایه مسطح‌کننده قرار دارد که ویژگی‌های چند بعدی خروجی را به یک بردار یک بعدی تبدیل می‌کند. این کار برای آماده‌سازی داده‌ها جهت ورود به لایه‌های کاملاً متصل انجام می‌شود.

در مرحله بعد، یک لایه کاملاً متصل قرار دارد که بردار ویژگی‌ها را به یک بردار با 100 نورون تبدیل می‌کند. این لایه تمام اتصالات ممکن بین نورون‌های ورودی و خروجی را دارد. پس از این لایه، یک تابع فعال‌سازی
\lr{ReLU}
وجود دارد که مشابه توابع فعال‌سازی قبلی عمل می‌کند و غیرخطی‌بودن را به شبکه اضافه می‌کند.

در پایان، یک لایه کاملاً متصل دیگر قرار دارد که بردار ویژگی‌ها را به یک بردار جدید با تعداد نورون‌هایی برابر با تعداد کلاس‌ها تبدیل می‌کند. این لایه، خروجی نهایی شبکه را تولید می‌کند که نشان می‌دهد هر ورودی به چه میزان به هر یک از کلاس‌ها تعلق دارد.

در انتها، یک لایه
\lr{Softmax} 
قرار داده شده که خروجی‌های نهایی شبکه را به توزیع احتمالاتی تبدیل می‌کند. این لایه باعث می‌شود که احتمال تعلق هر ورودی به هر کلاس به‌صورت عددی بین صفر و یک محاسبه شود، به طوری که مجموع این احتمالات برای همه کلاس‌ها برابر با یک باشد. این توزیع احتمالاتی در انتها برای انجام پیش‌بینی‌های نهایی به کار می‌رود. در پایان جهت درک بهتر می‌توانید ساختار این مدل را در شکل
\ref{cnn}
مشاهده نمایید.


\begin{figure}[b!]
	\centering
	\includegraphics[scale=0.463]{images/chap5/cnn.png}%
	\caption{
		ساختار مدل 
		\lr{CNN}.
	}
	\label{cnn}
	\centering
\end{figure}




\section{
مجموعه داده
	\lr{\texttt{\fontspec{Times New Roman} MNIST}}%
	\LTRfootnote{Modified National Institute of Standards and Technology}
}

مجموعه داده
\lr{MNIST}
یکی از مشهورترین و پر استفاده‌ترین مجموعه داده‌ها در زمینه یادگیری ماشین است. این مجموعه شامل تصاویر دست‌نویس از اعداد 0 تا 9 می‌باشد و به‌طور گسترده‌ای برای آموزش و ارزیابی مدل‌های مختلف یادگیری ماشین به کار گرفته می‌شود.
مجموعه داده
\lr{MNIST}
در دهه 1990 توسط یان لکون%
\LTRfootnote{Yann LeCun}،
کورینا کورتس%
\LTRfootnote{Corinna Cortes}
و کریستوفر برجس%
\LTRfootnote{Christopher Burges}
 ایجاد شد
 \cite{lecun1998gradient}.
 هدف اصلی این مجموعه داده، فراهم کردن یک مجموعه استاندارد برای ارزیابی الگوریتم‌های یادگیری ماشین و بینایی کامپیوتر بود.

مجموعه داده
\lr{MNIST}
شامل 70٬000 تصویر از ارقام دست‌نویس است که به دو بخش شامل مجموعه آموزش با 60٬000 تصویر و مجموعه تست با 10٬000 تصویر تقسیم می‌شود. هر تصویر دارای ابعاد
28$\times$28
پیکسل است که به‌صورت خاکستری%
\LTRfootnote{Grayscale}
ذخیره شده‌اند و هر پیکسل دارای مقداری بین 0 (سیاه) تا 255 (سفید) است. همچنین تمامی تصاویر با یک برچسب عددی بین 0 تا 9 همراه هستند که نمایانگر رقم موجود در تصویر می‌باشد.
چند نمونه از اعضای این مجموعه داده در شکل
\ref{mnist}%
، نمایش داده شده‌اند.

\begin{figure}[b!]
	\centering
	\includegraphics[scale=0.5]{images/chap5/mnist.png}%
	\caption{%
		چند نمونه از اعضای مجموعه داده
		\lr{MNIST}
		\cite{holzer2023dynamically}.
	}
	\label{mnist}
	\centering
\end{figure}


داده‌ها معمولاً در قالب دو فایل باینری شامل یکی برای تصاویر و دیگری برای برچسب‌ها ذخیره می‌شوند. هر تصویر به‌صورت یک بردار از اعداد بین 0 تا 255 با طول 784
(28$\times$28)
ذخیره می‌شود. به دلیل یکنواختی تصاویر و اندازه کوچک آن‌ها، نیاز به پیش‌پردازش پیچیده‌ای ندارند. یکی از مراحل پیش‌پردازش شامل نرمال‌سازی یا همان تبدیل مقادیر پیکسل‌ها به مقادیر بین 0 و 1 می‌باشد.

مجموعه داده
\lr{MNIST}
به عنوان یک نقطه شروع استاندارد برای آموزش و ارزیابی مدل‌های مختلف یادگیری عمیق و شبکه‌های عصبی استفاده می‌شود. محققان اغلب از
\lr{MNIST}
برای مقایسه کارایی الگوریتم‌های جدید با الگوریتم‌های موجود استفاده می‌کنند. این مجموعه شامل نمونه‌های متنوعی از ارقام دست‌نویس از افراد مختلف است که موجب می‌شود به عنوان یک معیار استاندارد برای مقایسه مدل‌ها و الگوریتم‌ها مورد استفاده قرار گیرد.

مجموعه داده
\lr{MNIST}
دارای مزایای زیادی از جمله سادگی، در دسترس بودن، استاندارد بودن و پراکندگی داده‌ها می‌باشد. با این حال، این مجموعه داده دارای معایبی نیز هست. به عنوان مثال، برای مسائل پیچیده‌تر و واقعی‌تر ممکن است
\lr{MNIST}
خیلی ساده باشد و نتواند چالش‌های واقعی را نشان دهد. همچنین، این مجموعه داده شامل تنها اعداد 0 تا 9 است و برای سایر کاربردهای دسته‌بندی تصویر ممکن است کافی نباشد.

کاربردهای عملی این مجموعه داده شامل آموزش شبکه‌های عصبی متفاوت برای بهبود دقت دسته‌بندی، تست و ارزیابی مدل‌های مختلف یادگیری عمیق و الگوریتم‌های بهینه‌سازی است. بسیاری از مدل‌ها و الگوریتم‌های پیشرفته امروزی با استفاده از مجموعه داده
\lr{MNIST}
توسعه و ارزیابی شده‌اند.

به‌طور کلی، مجموعه داده
\lr{MNIST}
با توجه به دلایل ذکر شده، یکی از مهم‌ترین و پراستفاده‌ترین مجموعه داده‌ها در زمینه یادگیری ماشین و بینایی کامپیوتر است. این مجموعه به محققان و دانشجویان کمک می‌کند تا مفاهیم پایه‌ای یادگیری ماشین را به خوبی درک کرده و الگوریتم‌های جدید را ارزیابی کنند.



اکنون نتایج مربوط به مجموعه داده
\lr{MNIST}
بررسی خواهد شد که شکل
\ref{result_mnist_mlp}
نتایج مقایسه روش
\lr{SimFedSwap}
با سایر روش‌های مرجع را با استفاده از مدل
\lr{MLP}
به تصویر می‌کشد.
همچنین، پارامترهای به‌کاررفته در این اجرا در جدول
\ref{tabel_parameter_mnist} 
به نمایش درآمده‌اند. نکته قابل توجه این است که منحنی‌های
\lr{FedAvg} 
و
\lr{FedSwap} 
به عنوان منحنی‌های نهایی و مرجع بر روی سایر منحنی‌ها قرار گرفته‌اند. در صورتی که رنگ متفاوتی در نمودار دیده شود، این موضوع نشان‌دهنده اختلاف عملکرد روش مربوطه در آن نقطه خواهد بود. این تغییر ممکن است نشان‌دهنده عملکرد بهتر یا ضعیف‌تر در مقایسه با دیگر روش‌ها باشد و می‌تواند به عنوان مبنایی برای مقایسه و تحلیل مورد توجه قرار گیرد.


\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
				\qquad\hspace{3mm}]{
		\label{result_mnist_mlp_mid}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/mnist/acc_mid_mlp.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
				\qquad\hspace{5mm}]{
		\label{result_mnist_mlp_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/mnist/acc_zoom_mlp.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{MNIST}
		با استفاده از مدل
		\lr{MLP}.
	}
	\label{result_mnist_mlp}
\end{figure}


%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[t!]
	\centering
	\caption{
	پارامترهای اجرا در مجموعه داده
	\lr{MNIST}
	}
	\label{tabel_parameter_mnist}
%	\scalebox{0.985}{
	\begin{tabular}{ccccccccccccc}
		\hline
		\specialcell{مجموعه\\داده} &
		\specialcell{نحوه\\جابه‌جایی} &
		\specialcell{توزیع\\داده} &
		$K$ &
		$B$ &
		$C$ &
		$SP$ &
		$\eta$ &
		$E$ &
		$h_1$ &
		$h_2$
		\\
		\hline
		\lr{MNIST} &
		\lr{MSS} &
		نرمال &
		\lr{10} &
		\lr{32} &
		\lr{1.0} &
		\lr{1.0} &
		\lr{0.001} &
		\lr{1} &
		\lr{5} &
		\lr{3}
		\\
	\end{tabular}
%	}
\end{table}


همان‌طور که در شکل
\ref{result_mnist_mlp} 
مشاهده می‌شود، روش‌های مبتنی‌بر جابه‌جایی به شکل بسیار ناچیزی از روش
\lr{FedAvg} 
نتایج مطلوب‌تری را ارائه داده‌اند. نکته قابل توجه این است که همه روش‌های مبتنی‌بر جابه‌جایی عملکردی مشابه داشته‌اند. برای بررسی دقیق‌تر این اجرا، منحنی‌های خطا در شکل
\ref{app_result_mnist_mlp}
پیوست، قابل مشاهده هستند.


در شکل
\ref{result_mnist_cnn}
همان آزمایش قبلی تکرار شده، با این تفاوت که این مرتبه از مدل شبکه عصبی
\lr{CNN}
استفاده شده است. همان‌طور که دیده می‌شود، تقریباً تمامی روش‌ها عملکرد مشابهی داشته‌اند. این نکته نشان می‌دهد که وقتی شبکه به راحتی به دقت بالایی می‌رسد، تفاوتی در نتایج بین روش‌ها دیده نمی‌شود. برای جزئیات بیشتر این اجرا، منحنی‌های خطا در شکل
\ref{app_result_mnist_cnn}
پیوست، آمده‌اند.


\begin{figure}[b]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_mnist_cnn_mid}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/mnist/acc_mid_cnn.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_mnist_cnn_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/mnist/acc_zoom_cnn.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{MNIST}
		با استفاده از مدل
		\lr{CNN}.
	}
	\label{result_mnist_cnn}
\end{figure}





\section{
	مجموعه داده
	\lr{\texttt{\fontspec{Times New Roman} CIFAR-10}}%
	\LTRfootnote{Canadian Institute For Advanced Research}
}


مجموعه داده
\lr{CIFAR-10}
یکی از معروف‌ترین و پرکاربردترین مجموعه داده‌های مورد استفاده در حوزه یادگیری ماشین و بینایی کامپیوتر است. این مجموعه داده توسط گروهی به سرپرستی الکس کریژفسکی%
\LTRfootnote{Alex Krizhevsky}
و جفری هینتون%
\LTRfootnote{Geoffrey Hinton}
در دانشگاه تورنتو گردآوری شده و برای ارزیابی و آزمایش مدل‌های یادگیری عمیق به کار می‌رود
\cite{krizhevsky2009learning}.


مجموعه داده
\lr{CIFAR-10}
شامل 60٬000 تصویر رنگی با اندازه
32$\times$32
پیکسل است که به 10 کلاس مختلف تقسیم شده‌اند. هر کلاس شامل 6000 تصویر است که به‌صورت مساوی بین مجموعه‌های آموزشی و آزمایشی توزیع شده‌اند. این کلاس‌ها شامل مواردی مانند هواپیما، اتومبیل، پرنده، گربه، گوزن، سگ، قورباغه، اسب، کِشتی و کامیون هستند. هر یک از این کلاس‌ها دارای تصاویری است که تنوع بالایی از زوایا، پس‌زمینه‌ها و شرایط نوری مختلف را شامل می‌شود.
در شکل
\ref{cifar10}%
، چند نمونه از هر کلاس در مجموعه داده
\mbox{\lr{CIFAR-10}}
به نمایش در آمده است.


\begin{figure}[b!]
	\centering
	\includegraphics[scale=0.7]{images/chap5/cifar10.png}%
	\caption{%
		چند نمونه از هر کلاس در مجموعه داده
		\lr{CIFAR-10}
		\cite{Evan2022CIFAR10}.
	}
	\label{cifar10}
	\centering
\end{figure}



یکی از ویژگی‌های مهم مجموعه داده
\lr{CIFAR-10}
تنوع بالای تصاویر در هر کلاس است. این تنوع باعث می‌شود که مدل‌های یادگیری عمیق نیاز به توانایی تعمیم‌دهی بالا برای تشخیص صحیح کلاس‌ها داشته باشند. این مجموعه داده برای آموزش و ارزیابی مدل‌های مختلفی مورد استفاده قرار می‌گیرد و بسیاری از پژوهش‌ها و مقالات علمی از آن به عنوان مبنای مقایسه عملکرد مدل‌ها استفاده کرده‌اند.

مجموعه داده
\lr{CIFAR-10}
به دو بخش آموزشی و آزمایشی تقسیم شده است. بخش آموزشی شامل 50٬000 تصویر و بخش آزمایشی شامل 10٬000 تصویر است. این تقسیم‌بندی، استانداردی برای ارزیابی مدل‌ها فراهم می‌کند، به طوری که مدل‌ها می‌توانند بر روی مجموعه آموزشی، آموزش دیده و سپس بر روی مجموعه آزمایشی ارزیابی شوند. این روش به محققان امکان می‌دهد تا عملکرد مدل‌ها را به‌صورت عینی و قابل تکرار مقایسه کنند.

به دلیل اندازه کوچک تصاویر (%
32$\times$32
پیکسل)، پردازش و آموزش مدل‌ها بر روی
\lr{CIFAR-10}
نسبتاً سریع و کم هزینه است. این ویژگی باعث شده تا مجموعه داده 
\lr{CIFAR-10}
برای آزمایش مدل‌ها بسیار مناسب باشد. بسیاری از ابزارها و چارچوب‌های%
\LTRfootnote{Frameworks}
یادگیری ماشین مانند
\lr{PyTorch}
و
\lr{TensorFlow}
شامل توابع و ابزارهای آماده برای بارگذاری و استفاده از این مجموعه داده هستند که این امر نیز به سهولت استفاده از آن کمک می‌کند.

در نهایت، مجموعه داده
\lr{CIFAR-10}
با ارائه تصاویری متنوع و چالش‌برانگیز در کلاس‌های مختلف، ابزاری قدرتمند برای آموزش و ارزیابی مدل‌های یادگیری عمیق فراهم می‌کند. این مجموعه داده نه تنها در پژوهش‌های دانشگاهی بلکه در صنعت نیز به عنوان معیاری برای ارزیابی پیشرفت‌ها در حوزه بینایی کامپیوتر استفاده می‌شود.



اکنون نتایج مربوط به مجموعه داده
\lr{CIFAR-10}
بررسی خواهد شد که شکل
\ref{result_cifar10_equal}
نتایج مقایسه روش
\lr{SimFedSwap}
با سایر روش‌های مرجع را با توزیع داده یکنواخت بین کاربران به تصویر می‌کشد.
پارامترهای استفاده شده در این آزمایش نیز در جدول
\ref{tabel_parameter_cifar10}
به نمایش درآمده‌اند.


\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_cifar10_equal_mid}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cifar10/acc_mid_equal.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_cifar10_equal_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cifar10/acc_zoom_equal.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{CIFAR-10}
		با توزیع داده یکنواخت.
	}
	\label{result_cifar10_equal}
\end{figure}


%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[t]
	\centering
	\caption{
		پارامترهای اجرا در مجموعه داده
		\lr{CIFAR-10}
	}
	\label{tabel_parameter_cifar10}
	%	\scalebox{0.985}{
		\begin{tabular}{ccccccccccccc}
			\hline
			\specialcell{مجموعه\\داده} &
			\specialcell{شبکه\\عصبی} &
			\specialcell{نحوه\\جابه‌جایی} &
			$K$ &
			$B$ &
			$C$ &
			$SP$ &
			$\eta$ &
			$E$ &
			$h_1$ &
			$h_2$
			\\
			\hline
			\lr{CIFAR-10} &
			\lr{Conv} &
			\lr{MSS} &
			\lr{10} &
			\lr{64} &
			\lr{1.0} &
			\lr{1.0} &
			\lr{0.001} &
			\lr{2} &
			\lr{3} &
			\lr{10}
			\\
		\end{tabular}
		%	}
\end{table}


همان‌طور که در شکل
\ref{result_cifar10_equal}
مشاهده می‌شود، روش‌های مبتنی‌بر جابه‌جایی نسبت به روش
\lr{FedAvg}
عملکرد متمایزی داشته‌اند. با این حال، این روش‌ها در یک سطح عملکردی نزدیک به هم قرار گرفته‌اند. به‌طور کلی، با وجود اختلافات جزئی، روش‌های مبتنی‌بر شباهت در مقایسه با روش
\lr{FedSwap}
کمی بهتر عمل کرده‌اند. برای آگاهی از جزئیات بیشتر، به منحنی‌های خطا در شکل
\ref{app_result_cifar10_equal}
پیوست، توجه نمایید.


در شکل
\ref{result_cifar10_normal}%
، آزمایش قبلی دوباره اجرا شده، اما این بار از توزیع داده نرمال استفاده شده است. مشاهده می‌شود که در این وضعیت نیز روش‌های مبتنی‌بر جابه‌جایی، عملکرد بهتری نسبت به روش
\lr{FedAvg}
داشته‌اند. البته، نتایج حاصل از روش‌های جابه‌جایی تقریباً مشابه بوده و تفاوت قابل توجهی بین آن‌ها دیده نمی‌شود. برای مشاهده جزئیات بیشتر، می‌توان به منحنی‌های خطا در شکل
\ref{app_result_cifar10_normal}
پیوست، مراجعه کرد.

\begin{figure}[t!]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_cifar10_normal_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cifar10/acc_base_normal.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_cifar10_normal_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cifar10/acc_zoom_normal.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{CIFAR-10}
		با توزیع داده نرمال.
	}
	\label{result_cifar10_normal}
\end{figure}




\section{
	مجموعه داده
	\lr{\texttt{\fontspec{Times New Roman} CINIC-10}}%
	\LTRfootnote{CIFAR-10 and ImageNet Combined}
}




مجموعه داده
\lr{CINIC-10}
یک مجموعه داده تصویری گسترده و متنوع است که برای ارزیابی عملکرد مدل‌های یادگیری ماشین به ویژه در زمینه‌های مرتبط با طبقه‌بندی تصاویر مورد استفاده قرار می‌گیرد
\cite{darlow2018cinic}.
این مجموعه داده، ترکیبی از تصاویر موجود در مجموعه‌ داده‌های معروف
\lr{CIFAR-10}
و
\lr{ImageNet}
است. این ترکیب به منظور ایجاد مجموعه‌ای گسترده‌تر و متنوع‌تر از تصاویر انجام شده است که می‌تواند به ارزیابی دقیق‌تر و واقع‌گرایانه‌تر مدل‌ها کمک کند.

مجموعه داده
\lr{CINIC-10}
شامل 270٬000 تصویر است که در 10 کلاس مختلف دسته‌بندی شده‌اند. هر کلاس شامل 27٬000 تصویر است که به دو بخش آموزشی و آزمایشی تقسیم شده‌اند. بخش آموزشی شامل 180٬000 تصویر و بخش آزمایشی شامل 90٬000 تصویر است. این تقسیم‌بندی منظم به محققان و مهندسان یادگیری ماشین این امکان را می‌دهد که به راحتی مدل‌های خود را آموزش داده، اعتبارسنجی و آزمایش کنند.

تصاویر موجود در
\lr{CINIC-10}
دارای ابعاد
32$\times$32
پیکسل هستند که مشابه ابعاد تصاویر موجود در مجموعه داده
\lr{CIFAR-10}
است. این ویژگی باعث می‌شود که مدل‌های از پیش آموزش دیده بر روی
\lr{CIFAR-10}
بتوانند به راحتی بر روی این مجموعه داده نیز مورد استفاده قرار گیرند و ارزیابی شوند. با این حال، تنوع بیشتر تصاویر در
\lr{CINIC-10}
نسبت به
\lr{CIFAR-10}
به دلیل ترکیب تصاویر از
\lr{ImageNet}،
چالشی جدی‌تر برای مدل‌های یادگیری ماشین فراهم می‌کند.
در شکل
\ref{cinic10}%
، تعدادی نمونه از کلاس خودرو در مجموعه داده
\mbox{\lr{CIFAR-10}}
به نمایش در آمده است.


\begin{figure}[b!]
	\centering
	\includegraphics[scale=0.5]{images/chap5/cinic10.png}%
	\caption{%
		تعدادی نمونه از کلاس خودرو در مجموعه داده
		\lr{CINIC-10}
		\cite{darlow2018cinic}.
	}
	\label{cinic10}
	\centering
\end{figure}



یکی از اهداف اصلی ایجاد
\lr{CINIC-10}،
افزایش تنوع و پیچیدگی تصاویر مورد استفاده برای آموزش و ارزیابی مدل‌ها بوده است. این مجموعه داده شامل تصاویری از دنیای واقعی است که در شرایط نوری مختلف و با پس‌زمینه‌های متنوع گرفته شده‌اند. این ویژگی به مدل‌ها کمک می‌کند تا به‌جای این که تنها بر روی مجموعه‌ای محدود از تصاویر آموزش ببینند، توانایی تعمیم‌دهی خود را به تصاویر جدید و غیرمنتظره نیز افزایش دهند.

در نهایت،
\lr{CINIC-10}
با هدف ارتقای استانداردهای ارزیابی مدل‌های یادگیری عمیق و بهبود عملکرد آن‌ها در مواجهه با داده‌های واقعی و متنوع ایجاد شده است. این مجموعه داده به محققان این امکان را می‌دهد که مدل‌های خود را در شرایط نزدیک به دنیای واقعی آزمایش کرده و نقاط ضعف و قوت آن‌ها را بهتر شناسایی کنند. به همین دلیل،
\lr{CINIC-10}
به عنوان یک ابزار ارزشمند در جامعه یادگیری ماشین شناخته می‌شود و به‌طور گسترده‌ای مورد استفاده قرار می‌گیرد.


اکنون نتایج مربوط به مجموعه داده
\lr{CINIC-10}
بررسی خواهد شد که شکل
\ref{result_cinic10}
نتایج مقایسه روش
\lr{SimFedSwap}
با سایر روش‌های مرجع را به تصویر می‌کشد.
همچنین، پارامترهای به کار رفته در این آزمایش در جدول
\ref{tabel_parameter_cinic10}
ارائه شده‌اند.

\begin{figure}[b!]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_cinic10_mid}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cinic10/acc_mid.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_cinic10_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cinic10/acc_zoom.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{CINIC-10}.
	}
	\label{result_cinic10}
\end{figure}


%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[b!]
	\centering
	\caption{
		پارامترهای اجرا در مجموعه داده
		\lr{CINIC-10}
	}
	\label{tabel_parameter_cinic10}
	%	\scalebox{0.985}{
		\begin{tabular}{ccccccccccccc}
			\hline
			\specialcell{مجموعه\\داده} &
			\specialcell{شبکه\\عصبی} &
			\specialcell{نحوه\\جابه‌جایی} &
			\specialcell{توزیع\\داده} &
			$K$ &
			$B$ &
			$C$ &
			$SP$ &
			$\eta$ &
			$E$ &
			$h_1$ &
			$h_2$
			\\
			\hline
			\lr{CINIC-10} &
			\lr{Conv} &
			\lr{MSS} &
			نرمال &
			\lr{30} &
			\lr{64} &
			\lr{0.5} &
			\lr{1.0} &
			\lr{0.001} &
			\lr{1} &
			\lr{2} &
			\lr{5}
			\\
		\end{tabular}
		%	}
\end{table}


در شکل
\ref{result_cinic10}
به‌وضوح می‌توان مشاهده کرد که روش‌های مبتنی‌بر جابه‌جایی در مقایسه با روش
\lr{FedAvg}%
، عملکرد متفاوتی داشته‌اند. هرچند، این روش‌ها همچنان در یک سطح عملکردی نزدیک به هم قرار دارند و تفاوت‌های عمده‌ای میان آن‌ها دیده نمی‌شود. برای بررسی دقیق‌تر، منحنی‌های خطا در شکل
\ref{app_result_cinic10}
پیوست، به تفصیل آمده‌اند.




\section{
	مجموعه داده
	\lr{\texttt{\fontspec{Times New Roman} FEMNIST}}%
	\LTRfootnote{Federated Extended MNIST}
}



مجموعه داده
\lr{FEMNIST}
یک مجموعه داده توسعه‌یافته از مجموعه مشهور
\lr{MNIST}
است که برای کاربردهای یادگیری فدرال طراحی شده است
\cite{caldas2018leaf}.
این مجموعه داده شامل 814٬255 تصویر است که در 62 کلاس مختلف دسته‌بندی شده‌اند و 10 درصد این داده‌ها به بخش آزمایشی تعلق دارند. مجموعه داده
\lr{FEMNIST}
از تصاویر دست‌نوشته به وجود آمده است که شامل اعداد و حروف الفبای انگلیسی می‌شود.

برخلاف مجموعه داده
\lr{MNIST}
که تنها شامل اعداد دست‌نوشته از صفر تا نه است، مجموعه داده
\lr{FEMNIST}
شامل حروف بزرگ و کوچک الفبای انگلیسی نیز می‌باشد. این ویژگی باعث می‌شود که
\lr{FEMNIST}
نسبت به
\lr{MNIST}
تنوع بیشتری داشته باشد و برای آزمایش مدل‌های پیچیده‌، مناسب‌تر باشد.
چند نمونه از اعضای این مجموعه داده در شکل
\ref{femnist}%
، نمایش داده شده‌اند.
در این مجموعه داده، تعداد داده‌ها در هر کلاس یکسان نیست و کلاس‌های مختلف دارای تعداد متفاوتی از داده‌ها هستند. شکل
\ref{count_all_classes}%
، تعداد داده‌های هر کلاس و نحوه نام‌گذاری آن‌ها را نشان می‌دهد.


\begin{figure}[b!]
	\centering
	\includegraphics[scale=0.5]{images/chap5/femnist.png}%
	\caption{%
		چند نمونه از اعضای مجموعه داده
		\lr{FEMNIST}
		\cite{holzer2023dynamically}.
	}
	\label{femnist}
	\centering
\end{figure}


\begin{figure}[t]
	\centering
	\includegraphics[scale=0.7]{images/chap5/count_all_classes.png}%
	\caption{%
تعداد داده‌های هر کلاس و نحوه نام‌گذاری در مجموعه داده
		\lr{FEMNIST}.
	}
	\label{count_all_classes}
	\centering
\end{figure}

همان‌طور که در شکل
\ref{count_all_classes}
مشاهده می‌شود، تعداد کلاس‌های 0 تا 9 که به ارقام 0 تا 9 اشاره دارند، به‌طور قابل‌توجهی بیشتر از سایر کلاس‌هاست و هر کدام حدود 40٬000 نمونه دارند. در بین کلاس‌های 10 تا 35 که مربوط به حروف بزرگ انگلیسی هستند، کلاس‌های \lr{S} و \lr{O} بیشترین تعداد نمونه را دارند. به نظر می‌رسد این سبک از جمع‌آوری داده به دلیل جلوگیری از اشتباه گرفتن کلاس \lr{O} با عدد صفر و کلاس \lr{S} با معادل حرف کوچک آن در کلاس‌های 36 تا 61 بوده باشد.


یکی از ویژگی‌های برجسته مجموعه داده
\lr{FEMNIST}،
نحوه سازماندهی داده‌ها است. این مجموعه داده بر اساس کاربران مختلف تقسیم‌بندی شده است، به طوری که هر کاربر دارای مجموعه‌ای از داده‌های دست‌نوشته خود است. این سازماندهی امکان آزمایش و ارزیابی روش‌های یادگیری فدرال را فراهم می‌کند، زیرا در یادگیری فدرال داده‌ها به‌صورت محلی بر روی دستگاه‌های کاربران، نگه‌داری می‌شوند و مدل‌ها بر روی این داده‌ها آموزش می‌بینند. این ویژگی به محققان اجازه می‌دهد تا سناریوهای واقعی‌تری از یادگیری فدرال را شبیه‌سازی و بررسی کنند.

مجموعه داده
\lr{FEMNIST}
به‌صورت پیش‌فرض شامل 3597 کاربر است که داده‌ها میان این کاربران توزیع شده‌اند. این توزیع، نه از لحاظ تعداد تصاویر بین کاربران و نه از لحاظ پوشش‌دهی کلاس‌ها در هر کاربر، یکسان نیست. با این حال، تعداد کاربران و نحوه توزیع داده‌ها میان آن‌ها را می‌توان به دلخواه تغییر داد.

برای بررسی حالت پیش‌فرض، می‌توان مشاهده کرد که هر کاربر چه تعداد کلاس را پوشش داده است. در شکل
\ref{clients_cover_classes}
قابل مشاهده است که هر کاربر چند کلاس را شامل می‌شود. به عنوان مثال، این شکل نشان می‌دهد که حدود 400 کاربر وجود دارند که هر کدام 58 کلاس را پوشش داده‌اند. همچنین برای بررسی تعداد تصاویری که در هر کاربر وجود دارد، می‌توان به شکل
\ref{clients_images}
توجه کرد. این شکل نشان می‌دهد که حدودا 480 کاربر وجود دارند که هر کدام 175 تصویر را شامل می‌شوند.



\begin{figure}[t]
	\centering
	\includegraphics[scale=0.7]{images/chap5/clients_cover_classes.png}%
	\caption{%
تعداد کلاس‌های پوشش‌داده شده توسط کاربران در مجموعه داده
		\lr{FEMNIST}.
	}
	\label{clients_cover_classes}
	\centering
\end{figure}


\begin{figure}[t!]
	\centering
	\includegraphics[scale=0.7]{images/chap5/clients_images.png}%
	\caption{%
		تعداد تصاویر هر یک از کاربران در مجموعه داده
		\lr{FEMNIST}.
	}
	\label{clients_images}
	\centering
\end{figure}



تصاویر در مجموعه داده
\lr{FEMNIST}
به‌صورت سیاه و سفید و با اندازه
28$\times$28
پیکسل هستند. هر تصویر نمایانگر یک کاراکتر دست‌نوشته است. این تصاویر از مجموعه داده
\lr{NIST}
استخراج شده‌اند و به‌صورت مناسبی برای کاربردهای یادگیری فدرال سازماندهی شده‌اند. در حقیقت این تصاویر شامل نویسه‌های مختلف از کاربران مختلف است که تنوع در سبک نوشتن و کیفیت دست‌نوشته‌ها را افزایش می‌دهد.


به‌طور کلی، مجموعه داده
\lr{FEMNIST}
یک ابزار قدرتمند برای تحقیقات در زمینه یادگیری فدرال است. با ارائه تنوع بالای داده‌ها و سازماندهی مناسب برای سناریوهای یادگیری فدرال، این مجموعه داده به محققان کمک می‌کند تا روش‌ها و الگوریتم‌های جدید را در محیط‌های واقعی‌تر آزمایش کنند. این ویژگی‌ها باعث شده تا
\lr{FEMNIST}
به عنوان یکی از مجموعه داده‌های مرجع در این حوزه شناخته شود و در بسیاری از تحقیقات علمی و صنعتی مورد استفاده قرار گیرد.



\subsection{
	رویکردهای پایه در مجموعه داده
	\lr{\texttt{\fontspec{Times New Roman} FEMNIST}}
}


این مجموعه داده در دو رویکرد مختلف بررسی خواهد شد. در رویکرد اول، داده‌ها بدون توجه به کاربران اصلی و تنها بر اساس کلاس‌های آن‌ها تفکیک می‌شوند. به این صورت که تمام داده‌های مربوط به هر کلاس جمع‌آوری شده و طبق یک توزیع مشخص بین تعدادی کاربر تقسیم می‌شوند. این روش به عنوان رویکرد کلاس‌بندی یا
\lr{FEMNISTclass}
شناخته می‌شود.

در رویکرد دوم، ساختار اصلی مجموعه داده تغییر نمی‌کند و تعداد کاربران همان تعداد پیش‌فرض باقی می‌ماند. همچنین داده‌ها دقیقا به همان شیوه‌ای که به هر کاربر اختصاص داده شده‌اند، حفظ می‌شوند. این روش به نام رویکرد نویسندگان یا
\lr{FEMNISTwriter}
نام‌گذاری شده است. در ادامه نتایج مربوط به هر کدام از این رویکرد‌ها به‌صورت مجزا بررسی خواهد شد.


\subsection{
	مقایسه نتایج در رویکرد کلاس‌بندی
	\lr{\texttt{\fontspec{Times New Roman} (FEMNISTclass)}}
}

نتایج مقایسه روش
\lr{SimFedSwap}
با دیگر روش‌های مرجع در شکل
\ref{result_FEMNISTclass}
نمایش داده شده‌اند که این آزمایش بر روی مجموعه داده
\lr{FEMNISTclass}
انجام شده است. پارامترهای مورد استفاده در این آزمایش نیز در جدول
\ref{tabel_parameter_FEMNISTclass}
ذکر شده‌اند.


\begin{figure}[b!]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_FEMNISTclass_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTclass/acc_base.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_FEMNISTclass_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTclass/acc_zoom.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{FEMNISTclass}.
	}
	\label{result_FEMNISTclass}
\end{figure}


%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[b!]
	\centering
	\caption{
		پارامترهای اجرا در مجموعه داده
		\lr{FEMNISTclass}
	}
	\label{tabel_parameter_FEMNISTclass}
	%	\scalebox{0.985}{
		\begin{tabular}{ccccccccccccc}
			\hline
			\specialcell{مجموعه\\داده} &
			\specialcell{شبکه\\عصبی} &
			\specialcell{نحوه\\جابه‌جایی} &
			\specialcell{توزیع\\داده} &
			$K$ &
			$B$ &
			$C$ &
			$SP$ &
			$\eta$ &
			$E$ &
			$h_1$ &
			$h_2$
			\\
			\hline
			\lr{FEMNISTclass} &
			\lr{Conv} &
			\lr{MSS} &
			یکنواخت &
			\lr{200} &
			\lr{1024} &
			\lr{1.0} &
			\lr{1.0} &
			\lr{0.001} &
			\lr{2} &
			\lr{5} &
			\lr{3}
			\\
		\end{tabular}
		%	}
\end{table}



از شکل
\ref{result_FEMNISTclass}
مشخص است که روش‌های مبتنی‌بر جابه‌جایی در مقایسه با
\lr{FedAvg}
عملکرد متفاوتی نشان می‌دهند، اما همچنان تفاوت‌های عملکردی بین آن‌ها محدود و نزدیک به هم است.
نکته قابل توجه این است که بسیاری از تغییرات در نمودارها به لحظات جابه‌جایی یا میانگین‌گیری مربوط می‌شوند.
برای جزئیات بیشتر و بررسی دقیق‌تر، می‌توان به منحنی‌های خطا که در شکل
\ref{app_result_FEMNISTclass}
پیوست آمده‌اند، مراجعه کرد.





\subsection{
	مقایسه نتایج در رویکرد نویسندگان
	\lr{\texttt{\fontspec{Times New Roman} (FEMNISTwriter)}}
}
نتایج مربوط به مقایسه روش
\lr{SimFedSwap}
با سایر روش‌های مرجع در شکل
\ref{result_FEMNISTwriter_one}
قابل مشاهده است. این آزمایش بر روی مجموعه داده
\lr{FEMNISTwriter}
اجرا شده و پارامترهای به‌کاررفته در آن نیز در جدول
\ref{tabel_parameter_FEMNISTwriter}
ذکر شده‌اند.


\begin{figure}[b!]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_FEMNISTwriter_one_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTwriter/acc_base_one.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_FEMNISTwriter_one_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTwriter/acc_zoom_one.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در یک اجرا بر روی مجموعه داده
		\lr{FEMNISTwriter}.
	}
	\label{result_FEMNISTwriter_one}
\end{figure}


%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[b!]
	\centering
	\caption{
		پارامترهای اجرا در مجموعه داده
		\lr{FEMNISTwriter}
	}
	\label{tabel_parameter_FEMNISTwriter}
	%	\scalebox{0.985}{
		\begin{tabular}{ccccccccccccc}
			\hline
			\specialcell{مجموعه\\داده} &
			\specialcell{شبکه\\عصبی} &
			\specialcell{نحوه\\جابه‌جایی} &
			\specialcell{توزیع\\داده} &
			$K$ &
			$B$ &
			$C$ &
			$SP$ &
			$\eta$ &
			$E$ &
			$h_1$ &
			$h_2$
			\\
			\hline
			\lr{FEMNISTwriter} &
			\lr{Conv} &
			\lr{MSS} &
			یکنواخت &
			\lr{3597} &
			\lr{64} &
			\lr{0.15} &
			\lr{1.0} &
			\lr{0.001} &
			\lr{1} &
			\lr{5} &
			\lr{3}
			\\
		\end{tabular}
		%	}
\end{table}


در شکل
\ref{result_FEMNISTwriter_one}
مشاهده می‌شود که روش‌های مبتنی‌بر جابه‌جایی نتایجی متفاوت از روش
\lr{FedAvg}
ارائه داده‌اند. اما نکته مهم، برتری قابل توجه روش‌های مبتنی‌بر شباهت نسبت به
\lr{FedSwap}
است. این اولین آزمایشی است که در آن روش‌های شباهت محور توانسته‌اند عملکرد بهتری را به‌طور معناداری ارائه کنند. برای اطلاعات بیشتر و تحلیل دقیق‌تر، می‌توان به منحنی‌های خطا در شکل
\ref{app_result_FEMNISTwriter_one}
پیوست، مراجعه کرد.



با بهبود نتایج، این پرسش پیش می‌آید که آیا این برتری در شرایط استفاده از چندین
\lr{Seed}
متفاوت، همچنان پابرجا خواهد بود. برای پاسخ به این سوال، آزمایش قبلی با پنج
\lr{Seed}
مختلف تکرار شده و میانگین نتایج در شکل
\ref{result_FEMNISTwriter_seed}
نمایش داده شده‌اند. نکته قابل توجه این است که اختلاف روش مبتنی‌بر شباهت با روش
\lr{FedSwap}%
، دیگر به وضوح قبلی دیده نمی‌شود و تنها، بهبودی حدود یک درصد در میانگین پنج اجرا مشاهده می‌شود.
\begin{figure}[t!]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_FEMNISTwriter_seed_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTwriter/acc_base_seed.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_FEMNISTwriter_seed_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTwriter/acc_zoom_seed.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در میانگین پنج اجرا بر روی مجموعه داده
		\lr{FEMNISTwriter}.
	}
	\label{result_FEMNISTwriter_seed}
\end{figure}
همچنین باید به این نکته توجه شود که تغییر
\lr{Seed}
در نمودارهای پیشین، تفاوت چشم‌گیری در خروجی ایجاد نمی‌کردند.
برای بررسی جزئیات بیشتر، منحنی‌های خطا در شکل
\ref{app_result_FEMNISTwriter_seed}
پیوست ارائه شده‌اند.


بنابراین می‌توان نتیجه گرفت که با افزایش تعداد کاربران و داده‌های مربوط به آن‌ها، روش‌های مبتنی بر شباهت، هرچند به میزان کم، می‌توانند عملکرد بهتری نشان دهند.
باید به این نکته توجه داشت که دقت کلی که در این مجموعه داده به 50 درصد رسید، وابسته به طراحی شبکه عصبی است. با بهینه‌سازی این شبکه، می‌توان به دقت بالاتری دست یافت. با این حال، این بهینه‌سازی تأثیری بر مقایسه بین روش‌ها نخواهد داشت، زیرا همه روش‌ها به‌طور همزمان به دقت بهتری دست خواهند یافت.




\section{
	مقایسه جابه‌جایی حریصانه با جابه‌جایی حداقل شباهت در روش
	\lr{\texttt{\fontspec{Times New Roman} SimFedSwap}}
}

شکل
\ref{result_MSS_vs_GS_cifar10}
عملکرد دو روش جابه‌جایی حریصانه و جابه‌جایی حداقل شباهت را در الگوریتم
\lr{SimFedSwap}
مقایسه می‌کند. این ارزیابی روی مجموعه داده
\lr{CIFAR-10}
و با توزیع یکنواخت داده‌ها میان کاربران انجام شده است. مشخصات پارامترهای این آزمایش در جدول
\ref{tabel_parameter_cifar10}
آمده است.


\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_MSS_vs_GS_cifar10_mid}
		\includegraphics*[width=.48\textwidth]{images/chap5/result_MSS_vs_GS/cifar10/acc_mid.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_MSS_vs_GS_cifar10_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result_MSS_vs_GS/cifar10/acc_zoom.png}
	}
	\caption{
		مقایسه منحنی‌های دقت بین
		\lr{MSS}
		و
		\lr{GS}%
		، در مجموعه داده
		\lr{CIFAR-10}
		با توزیع داده یکنواخت.
	}
	\label{result_MSS_vs_GS_cifar10}
\end{figure}


بر اساس نتایج شکل
\ref{result_MSS_vs_GS_cifar10}%
، عملکرد این دو روش بسیار مشابه بوده و تفاوت قابل‌توجهی مشاهده نمی‌شود. برای اطلاعات بیشتر، می‌توان به منحنی‌های خطا در شکل
\ref{app_result_MSS_vs_GS_cifar10}
پیوست، مراجعه کرد.


شکل
\ref{result_MSS_vs_GS_FEMNISTwriter}
عملکرد دو روش جابه‌جایی حریصانه و جابه‌جایی حداقل شباهت را در الگوریتم
\lr{SimFedSwap}
مقایسه می‌کند. این آزمایش بر روی مجموعه داده
\lr{FEMNISTwriter}
انجام شده و پارامترهای مربوط به این بررسی در جدول
\ref{tabel_parameter_FEMNISTwriter}
آورده شده است.


\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_MSS_vs_GS_FEMNISTwriter_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result_MSS_vs_GS/FEMNISTwriter/acc_base.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_MSS_vs_GS_FEMNISTwriter_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result_MSS_vs_GS/FEMNISTwriter/acc_zoom.png}
	}
	\caption{
		مقایسه منحنی‌های دقت بین
		\lr{MSS}
		و
		\lr{GS}%
		، در مجموعه داده
		\lr{FEMNISTwriter}.
	}
	\label{result_MSS_vs_GS_FEMNISTwriter}
\end{figure}



نتایج به دست آمده از شکل
\ref{result_MSS_vs_GS_FEMNISTwriter}
نشان می‌دهد که معیار
\lr{OSAD}
با استفاده از جابه‌جایی حریصانه عملکردی مشابه روش
\lr{FedSwap}
داشته است. اما روش‌های
\lr{CKA}
با استفاده از هسته‌های خطی و گاوسی به تدریج عملکرد خود را بهبود بخشیده و به نتایج بهتری دست یافته‌اند. برای اطلاعات دقیق‌تر، منحنی‌های خطا در شکل
\ref{app_result_MSS_vs_GS_FEMNISTwriter}
پیوست، قابل بررسی هستند.



\section{
	تحلیل کاهش تعداد کاربران در هر دور و افزایش تعداد کل دورها در روش
	\lr{\texttt{\fontspec{Times New Roman} SimFedSwap}}
}
در این بخش بررسی می‌شود که اگر تعداد کاربران شرکت کننده در هر دور به‌طور قابل توجهی کاهش یابد و در مقابل تعداد کل دورها افزایش پیدا کند، آیا مدل سراسری همچنان آموزش دیده و به همگرایی خواهد رسید.

شکل
\ref{result_lowC_highStep_cinic10}
به تحلیل تأثیر کاهش تعداد کاربران در هر دور و افزایش تعداد دورهای کلی در الگوریتم
\lr{SimFedSwap}
پرداخته است. این آزمایش با استفاده از مجموعه داده
\lr{CINIC-10}
انجام شده و پارامترهای مورد استفاده، در جدول
\ref{tabel_parameter_lowC_highStep_cinic10}
به نمایش درآمده‌اند.

\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_lowC_highStep_cinic10_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result_lowC_highStep/cinic10/acc_base.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_lowC_highStep_cinic10_mid}
		\includegraphics*[width=.48\textwidth]{images/chap5/result_lowC_highStep/cinic10/acc_mid.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{CININC-10}
		با کاهش مشارکت کاربران و افزایش  کل دورها.
	}
	\label{result_lowC_highStep_cinic10}
\end{figure}


%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[t]
	\centering
	\caption{
		پارامترهای اجرا در مجموعه داده
		\lr{CINIC-10}
		با کاهش مشارکت کاربران و افزایش  کل دورها
	}
	\label{tabel_parameter_lowC_highStep_cinic10}
	%	\scalebox{0.985}{
		\begin{tabular}{ccccccccccccc}
			\hline
			\specialcell{مجموعه\\داده} &
			\specialcell{شبکه\\عصبی} &
			\specialcell{نحوه\\جابه‌جایی} &
			\specialcell{توزیع\\داده} &
			$K$ &
			$B$ &
			$C$ &
			$SP$ &
			$\eta$ &
			$E$ &
			$h_1$ &
			$h_2$
			\\
			\hline
			\lr{CINIC-10} &
			\lr{Conv} &
			\lr{MSS} &
			نرمال &
			\lr{200} &
			\lr{64} &
			\lr{0.1} &
			\lr{1.0} &
			\lr{0.001} &
			\lr{1} &
			\lr{5} &
			\lr{3}
			\\
		\end{tabular}
		%	}
\end{table}


بر اساس نتایج ارائه‌شده در شکل
\ref{result_lowC_highStep_cinic10}%
، حتی با وجود مشارکت کم کاربران در هر دور، مدل سراسری توانسته است به همگرایی برسد. اما برای این کار به بیش از 6000 دور احتیاج داشته است. همچنین، تمامی روش‌ها تقریبا عملکرد مشابهی را ارائه داده‌اند.
برای جزئیات بیشتر، منحنی‌های خطا در شکل
\ref{app_result_lowC_highStep_cinic10}
پیوست، نشان داده شده‌اند.




شکل
\ref{result_lowC_highStep_FEMNISTclass}
تأثیر کاهش تعداد کاربران شرکت‌ کننده در هر دور و افزایش تعداد کل دورها را در الگوریتم
\lr{SimFedSwap}
بررسی می‌کند. این ارزیابی بر پایه مجموعه داده 
\lr{FEMNISTclass}
صورت گرفته و پارامترهای مورد استفاده نیز در جدول
\ref{tabel_parameter_FEMNISTclass}
آورده شده‌اند، با این تفاوت که مقدار
\(C\)
برابر با 0٫1 تنظیم شده است.

\begin{figure}[b]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_lowC_highStep_FEMNISTclass_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result_lowC_highStep/FEMNISTclass/acc_base.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_lowC_highStep_FEMNISTclass_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result_lowC_highStep/FEMNISTclass/acc_zoom.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{FEMNISTclass}
		با کاهش مشارکت کاربران و افزایش  کل دورها.
	}
	\label{result_lowC_highStep_FEMNISTclass}
\end{figure}


نتایج موجود در شکل
\ref{result_lowC_highStep_FEMNISTclass}
نشان می‌دهد که حتی با کاهش تعداد کاربران در هر دور، مدل سراسری موفق به همگرایی می‌شود. با این حال، این فرآیند به حدود 160 دور نیاز داشته است، در حالی که در شکل
\ref{result_FEMNISTclass_base}%
، همگرایی تنها با 45 دور به دست آمده بود. این در صورتی است که تمام روش‌های مبتنی‌بر جابه‌جایی عملکرد مشابهی از خود نشان داده‌اند. برای بررسی دقیق‌تر این نتایج، می‌توان به منحنی‌های خطا در شکل
\ref{app_result_lowC_highStep_FEMNISTclass}
پیوست، مراجعه کرد.



\section{بررسی نحوه پیاده‌سازی کد، سخت‌افزار مورد استفاده و زمان اجرای کدها}

تمامی کدهای مورد استفاده در این پژوهش با کتابخانه
\lr{PyTorch}
پیاده‌سازی شده‌اند. همان‌طور که در پروپوزال بیان شده بود، ابتدا کتابخانه‌های
\lr{TensorFlow Federated (TFF)},
\lr{PySyft}
و
\lr{Flower}
مد نظر بودند اما پس از پیاده‌سازی اولیه و رسیدن به مرحله مقایسه شبکه‌های عصبی و جابه‌جایی آن‌ها بین کاربران، مشخص شد که این کتابخانه‌ها ساختار مورد نیاز برای این کار را ندارند. همچنین، افزودن این ویژگی‌ها به کتابخانه‌های مذکور زمان‌بر بوده و این کتابخانه‌ها شامل بسیاری از امکانات غیرضروری برای این پژوهش بودند. به همین دلیل، تصمیم گرفته شد که پیاده‌سازی از پایه با استفاده از
\lr{PyTorch}
انجام شود. همچنین کد این پژوهش به‌صورت متن باز در
\lr{Github}
موجود می‌باشد.


در ابتدا، اجرای تمامی آزمایش‌ها با درصد کمی از مجموعه داده‌ها در محیط 
\lr{Google Colab}
صورت گرفت. برای بهینه‌سازی فرآیند، از چند حساب کاربری مختلف استفاده شد تا امکان ذخیره تنظیمات در پایان هر دور و ادامه اجراها در حساب‌های دیگر فراهم شود. پس از تکمیل کد، بررسی‌های نهایی توسط کلاستر محاسباتی که از سوی دانشکده فراهم شده بود، انجام گرفت. همچنین، لازم است از سخت‌افزارهای ارائه‌شده قدردانی شود. در نهایت، تمام نتایج مشاهده‌شده در نمودارها با سیستمی که مشخصات آن در جدول 
\ref{tabel_system_configuration}
آمده است، اجرا شده‌اند.
برای نمونه، در آزمایش شکل
\ref{result_lowC_highStep_cinic10}%
، هر دور به‌طور میانگین 70 ثانیه زمان برده که برای 6000 دور، ۴٫۸ روز به ازای هر منحنی زمان نیاز بوده است. همچنین، اجرای نتایج مشاهده شده در شکل
\ref{result_FEMNISTclass}
به‌طور میانگین در هر دور 40 دقیقه زمان برده که برای 45 دور، به ۱٫۲۵ روز زمان نیاز داشته است.



\begin{table}[b]
	\centering
	\caption{مشخصات سیستمی کلاستر اجرای کدها}
	\label{tabel_system_configuration}
	\begin{tabular}{ll}
		\hline
		مدل & قطعه \\
		\hline
		\lr{Intel(R) Core(TM) i7-9700K CPU @ 3.60GHz (8 CPUs)} & \lr{CPU} \\
		\lr{32 GB} & \lr{RAM} \\
		\lr{NVIDIA GeForce RTX 2080 Ti} & \lr{GPU} \\
		\lr{Samsung SSD 860 EVO 250GB} & \lr{Drive}
	\end{tabular}
\end{table}


این زمان‌ها مربوط به آزمایش‌هایی با تعداد کاربران کم بودند. در صورت افزایش تعداد کاربران، مرحله بررسی شباهت و جابه‌جایی مدل‌ها، به زمان زیادی نیاز خواهد داشت. به ‌عنوان مثال، در اجرای مجموعه داده
\lr{FEMNISTwriter}
با 3597 کاربر و مشارکت 15 درصد از آن‌ها (540 کاربر) در هر دور، بررسی شباهت و جابه‌جایی حدود 20 دقیقه زمان می‌برد.

برای نمونه، در آزمایش مشاهده شده در شکل
\ref{result_FEMNISTwriter_one}
با توجه به پارامترهای اجرا، از 610 دور، 81 دور به بررسی شباهت و جابه‌جایی اختصاص یافته که هر کدام 20 دقیقه زمان برده و به ازای هر 529 دور باقی‌مانده، 50 ثانیه صرف شده است. در مجموع، اجرای هر منحنی به ۱٫۴۳ روز زمان نیاز داشته است. اگر این آزمایش‌ها با میانگین پنج
\lr{Seed}
انجام شوند، زمان اجرا به شکل قابل‌توجهی افزایش خواهد یافت. بنابراین، در برخی از نتایج، بررسی تمامی روش‌های مشابهت به دلیل زمان‌بر بودن، انجام نشده‌اند.



برای استفاده بهینه از سخت‌افزار، به‌جای اجرای یک کد، دو کد به‌صورت همزمان اجرا شده‌اند تا نهایت استفاده از منابع سخت‌افزاری صورت گیرد. همانطور که در شکل
\ref{task_manager}
مشاهده می‌شود،
\begin{figure}[b!]
	\centering
	\includegraphics[scale=0.225]{images/chap5/task_manager_inverted_color.png}%
	\caption{%
		میزان استفاده از سخت‌افزار موجود، هنگام اجرای کد.
	}
	\label{task_manager}
	\centering
\end{figure}
در بیشتر اوقات حدود 99 درصد منابع
\lr{CUDA}%
\LTRfootnote{Compute Unified Device Architecture}
در حال استفاده بوده است.



این بخش به منظور آگاهی‌رسانی به محققانی است که قصد دارند در این زمینه فعالیت کنند. اما باید توجه داشت که در دنیای واقعی، به دلیل مجزا بودن کاربران، زمان اجرا به‌صورت متمرکز محاسبه نمی‌شود.


\section{جمع‌بندی}
در این فصل، دو مدل کلیدی شبکه عصبی، یعنی پرسپترون چندلایه
\lr{(MLP)}
و شبکه عصبی پیچشی
\lr{(CNN)}
که طراحی و به کار گرفته شدند، مورد بررسی قرار گرفتند. سپس، مجموعه داده‌های مختلف معرفی و نتایج مقایسه روش 
\lr{SimFedSwap} 
با سایر روش‌های مرجع ارائه شد. در اغلب مجموعه داده‌ها، تفاوت زیادی بین روش‌ها مشاهده نشد، اما در مجموعه داده 
\lr{FEMNISTwriter}%
، روش‌های مبتنی‌بر شباهت عملکرد بهتری از روش‌های مرجع داشتند. این تحلیل‌ها نشان می‌دهد که وقتی شبکه به راحتی به دقت بالا می‌رسد و تعداد کاربران محدود است، اختلاف بین روش‌ها چندان قابل توجه نیست. با این حال، در مجموعه داده‌های پیچیده‌تر و با افزایش تعداد کاربران، این تفاوت‌ها آشکارتر می‌شوند.
همچنین، کاهش تعداد کاربران در هر دور و افزایش تعداد کل دورها به همگرایی مدل منجر می‌شود، اما زمان بیشتری برای رسیدن به این همگرایی لازم است.
