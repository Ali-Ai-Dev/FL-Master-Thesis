% Chapter 2
\chapter{مفاهیم پایه در یادگیری فدرال}

\section{مقدمه}
توزیع داده‌ها بین کاربران در یادگیری فدرال ممکن است با چالش‌ها و مشکلات گوناگونی روبرو شود. یکی از مشکلات اساسی، اختلافات و ناسازگاری‌هایی است که ممکن است در فرآیند آموزش میان کاربران یا دستگاه‌های مختلف پدید آید. اگر این چالش‌ها پیش از آغاز فرآیند مدل‌سازی به درستی شناسایی نشده و راه‌حل‌های مناسبی برای آن‌ها اتخاذ نشود، مدل نهایی احتمالاً با مشکلاتی همچون کاهش دقت و عملکرد روبرو خواهد شد. این مسئله یکی از بزرگترین موانع در مسیر یادگیری فدرال است و نیازمند دقت و استفاده از روش‌های خلاقانه برای حل آن است.

در این فصل، ابتدا به بررسی چالش‌های موجود در یادگیری فدرال پرداخته خواهد شد و سپس دیدگاه‌های مقالات علمی در مورد هر یک از این چالش‌ها به صورت کلی بررسی می‌شود. در ادامه، بیان ریاضی یادگیری فدرال توضیح داده می‌شود و نهایتاً به رویکردهای کلی و اساسی برای حل این چالش‌ها اشاره خواهد شد.


\section{چالش‌های موجود در یادگیری فدرال و نگاه کلی مقالات به آن‌ها}
با وجود مزیت‌های بسیار زیاد نسبت به روش‌های سنتی یادگیری ماشین، یادگیری فدرال به دلیل ساختار شبکه یادگیری با چالش‌های گوناگونی روبرو است. چالش‌های اصلی یادگیری فدرال عبارتند از:


\subsection{تبادل داده}
تبادل داده بین سرور و کاربران به دلیل مشکلات پهنای باند و ارتباطات شبکه‌ای اصولا کار پر هزینه‌ای می‌باشد. یکی از دلایل اصلی پرهزینه بودن این ارتباطات، حجم بالای داده‌هایی است که باید بین دستگاه‌های کاربری و سرور منتقل شوند.
معمولاً مشکلات ارتباطی به انتقال‌های بسیار زیاد به‌روزرسانی‌های مدل بین گره‌های محاسباتی نسبت داده می‌شود. با افزایش تعداد پارامترها در مدل‌های پیشرفته، اندازه این مدل‌ها نیز به طور متناسب بزرگ می‌شود
\cite{wang2018atomo}.

از سوی دیگر، تعداد زیادی از دستگاه‌های کاربران نهایی در فرآیند آموزش مدل‌ها مشارکت دارند که این امر می‌تواند هزینه‌های ارتباطی را به طور قابل توجهی افزایش دهد. همچنین، به دلیل مشکلات ارتباطی، در بسیاری از مواقع همه دستگاه‌ها در هر چرخه از فرآیند آموزش شرکت نمی‌کنند که این مسئله نیز باعث افزایش هزینه‌ها و پیچیدگی‌های مرتبط با انتقال داده‌ها می‌شود.


\subsection{
	ناهمگنی‌های سیستمی
\LTRfootnote{Systems Heterogeneity}
}
در دنیای یادگیری فدرال، دستگاه‌ها از نظر حافظه، توان محاسباتی و ارتباطات بسیار با یکدیگر متفاوت هستند. این تفاوت‌ها ممکن است از اختلافاتی مانند تفاوت در پردازنده، نوع حافظه، نوع اتصال شبکه و نیاز به انرژی ناشی شود. محدودیت‌های موجود در شبکه و سیستمی می‌توانند باعث ایجاد وضعیت‌هایی شوند که برخی از دستگاه‌ها در یک زمان معین در دسترس نباشند. برای مثال، اگر تعداد زیادی دستگاه همزمان درخواست ارسال داشته باشند، ممکن است برخی از آن‌ها به دلیل پهنای باند محدود یا محدودیت‌های سخت‌افزاری، قادر به ارسال درخواست نشوند. همچنین، ممکن است یک دستگاه فعال، به دلیل مشکلاتی مانند اختلالات در شبکه یا مصرف اضافی انرژی، از فرآیند یادگیری خارج شود.

این تفاوت‌های سیستمی، یکی از چالش‌های یادگیری فدرال محسوب می‌شوند و می‌توانند باعث افزایش تأخیر و ایجاد اشکالات در سیستم شوند. بنابراین، برای رفع این مشکلات، روش‌های یادگیری فدرال باید توانایی پیش‌بینی دقیق تعداد دستگاه‌هایی که در هر فرآیند شرکت می‌کنند را داشته باشند. همچنین، باید بتوانند در برابر دستگاه‌هایی که در حین عملیات دچار مشکل شده و از دسترس خارج می‌شوند، مقاومتی مناسب داشته باشند
\cite{li2020federated}.


\subsection{
	ناهمگنی‌های آماری
\LTRfootnote{Statistical Heterogeneity}
}
 طریقه تولید و جمع‌آوری داده‌ها بین دستگاه‌ها به شکل گوناگونی انجام می‌شود. این مجموعه داده‌ها اغلب مستقل از یکدیگر نیستند و ارتباطات و اتصالات میان آن‌ها وجود دارد. این الگوی تولید داده‌ها، با فرض استقلال و توزیع یکنواخت داده%
 \LTRfootnote{Independent and Identically Distributed}
  \lr{(IID)}
  در مسائل بهینه‌سازی متضاد است، که باعث ایجاد پیچیدگی در مدل‌سازی، تجزیه و تحلیل نظری و ارزیابی عملکرد راه‌حل‌ها می‌شود. در نتیجه، هرچند هدف نهایی یادگیری یک مدل سراسری است، اما روش‌های جایگزین مانند آموزش همزمان مدل‌های محلی جداگانه از طریق یادگیری چندوظیفه‌ای%
  \LTRfootnote{Multi-Tasking}
  و فرایادگیری%
   \LTRfootnote{Meta Learning}%
  ، به عنوان گزینه‌های جایگزین مطرح شده‌اند
   \cite{li2020federated}.
   
\subsection{حریم شخصی}
یکی از چالش‌های اساسی در یادگیری فدرال، حفظ حریم شخصی است که در این روش، داده‌های حساس و شخصی در اختیار بخش‌های مختلفی از شبکه قرار می‌گیرند. در این روش، دستگاه‌های محلی اطلاعاتی از کاربران جمع‌آوری و به سرور ارسال می‌کنند تا مدل‌های یادگیری مشترک را به‌روزرسانی کنند. این ارتباطات می‌توانند حاوی اطلاعات حساسی باشند که می‌توانند به راحتی به شناسایی فرد یا فرآیندهای حیاتی او منجر شوند.

یکی از مشکلات اساسی در اینجا این است که حتی با استفاده از روش‌های رمزنگاری و حفظ امنیت، اطلاعات معینی همچنان ممکن است به سرور ارسال شود که احتمالاً می‌تواند حریم شخصی را نقض کند. به‌طور خاص، اگر داده‌های حساس بدون رمزنگاری به سرور ارسال شوند یا اگر حتی اطلاعاتی که قابلیت شناسایی فرد را دارند به صورت رمزگذاری نشده ارسال شوند، حریم شخصی کاربران مورد تهدید قرار می‌گیرد.


\section{نگاه مقالات مرتبط به چالش‌های موجود}

\subsection{تبادل داده}
با استفاده از فشرده‌سازی داده‌ها، می‌توان هزینه‌های ارتباطی را به طور قابل توجهی کاهش داد. دو روش جهت مدیریت هزینه‌های بالای ارتباطات در فرایند یادگیری فدرال مورد بررسی قرار گرفته است. این روش‌ها به فشرده‌سازی داده‌هایی که از دستگاه‌های کاربری به سرور مرکزی ارسال می‌شوند متمرکز شده‌اند. این فشرده‌سازی اطلاعات ارسالی به گونه‌ای است که حجم داده‌های ارسالی کم شده و در نتیجه، هزینه‌های مربوط به ارتباطات نیز کاهش یابد
\cite{konevcny2016federated}.

در روشی به نام
\lr{PCFL}%
\LTRfootnote{Privacy Communication efficient Federated Learning}
که یک رویکرد حفظ حریم خصوصی و البته بسیار کارآمد از نظر ارتباطی می‌باشد، شامل سه جزء کلیدی است که به ترتیب از فشرده‌سازی دوطرفه، فشرده‌سازی مکانی گرادیان‌ها و یک پروتکل حفظ حریم خصوصی که خود از تقسیم راز%
\LTRfootnote{Secret Sharing}
 و رمزنگاری همگام%
 \LTRfootnote{Homomorphic Encryption}
  برای محافظت از حریم خصوصی داده‌ها استفاده می‌کند، بهره گرفته است
  \cite{fang2021privacy}.


\subsection{ناهمگنی سیستمی و آماری}
برای مقابله با ناهمگنی سیستمی و آماری، روش‌هایی مانند تعادل در به‌روزرسانی مدل مطرح شده است. در این روش، وزن‌دهی به نمونه‌ها بر اساس میزان نیاز به آموزش در هر دستگاه صورت می‌گیرد. این کار باعث می‌شود که دستگاه‌های با حجم داده کمتر، وزن بیشتری در به‌روزرسانی مدل داشته باشند
\cite{konevcny2015federated}.
در رویکرد دیگری به نام یادگیری فعال، دستگاه‌هایی که داده‌های خود را به سرور ارسال می‌کنند، فعالیت خود را به نحوی تنظیم می‌کنند که مدل از داده‌های مهم‌تر و کمتر دیده شده بیشتر یاد می‌گیرد. این روش می‌تواند به تعادل در آموزش مدل کمک کند و از ناهمگنی سیستمی جلوگیری کند
\cite{konevcny2016federated}.

یک روش دیگر برای حل مشکل ناهمگنی سیستمی و آماری در یادگیری فدرال استفاده از رویکرد ترکیبی یا ترکیب روش‌های یادگیری محلی است. در این رویکرد، به جای استفاده از یک الگوریتم یادگیری مشترک برای تمام دستگاه‌ها، از چندین الگوریتم یادگیری محلی با تنوع مدل‌ها و تنظیمات مختلف استفاده می‌شود. سپس، اطلاعات مدل‌های محلی روی سرور یا گره مرکزی جمع‌آوری می‌شود و با استفاده از ترکیب این اطلاعات، یک مدل یادگیری مشترک بروزرسانی خواهد شد
\cite{konevcny2015federated}.


\subsection{حریم شخصی}
در روش حفظ حریم خصوصی تفاضلی%
\LTRfootnote{Differential Privacy}
با افزودن نویز به نتایج محاسبات یا به داده‌های ورودی، اطمینان حاصل می‌کند که حضور یا عدم حضور یک نمونه داده خاص در مجموعه داده‌ها، تأثیر قابل توجهی بر خروجی محاسبات نداشته باشد. این روش به ویژه برای حفظ حریم خصوصی در یادگیری فدرال مفید است زیرا از افشای اطلاعات حساس از طریق پارامترهای مدل جلوگیری می‌کند
\cite{hasan2023security}.

رویکرد رمزنگاری همگام امکان محاسبه روی داده‌های رمزنگاری شده را بدون نیاز به رمزگشایی آن‌ها فراهم می‌کند. این تکنیک به ویژه در یادگیری فدرال برای حفظ حریم خصوصی داده‌ها در حین انجام محاسبات مفید است زیرا نیاز به تغییر ماهیت داده نبوده و چون جابجایی در یادگیری فدرال بسیار زیاد رخ می‌دهد، این روش بسیار کارا خواهد بود
\cite{yin2021comprehensive}.



\section{بیان ریاضی یادگیری فدرال}
برای ورود به مباحث ریاضی پایه در یادگیری فدرال، ابتدا باید به تعریف دقیق مسئله بهینه‌سازی مرکزی بپردازیم که در این حوزه مطرح می‌شود. در یادگیری فدرال، هدف اصلی یافتن مجموعه‌ای از پارامترهای مدل است که عملکرد کلی مدل را بر روی داده‌های توزیع‌شده بین تعداد زیادی دستگاه بهینه کند. هر دستگاه دارای داده‌های محلی است و یک تابع هزینه محلی بر اساس این داده‌ها برای آن دستگاه تعریف می‌شود. مسئله بهینه‌سازی کلی در یادگیری فدرال به دنبال کمینه کردن مجموع وزنی این توابع هزینه محلی است تا یک مدل جامع و یکپارچه حاصل شود.

ما یک طرح به‌روزرسانی همزمان را فرض می‌کنیم که به صورت دوره‌های ارتباطی پیش می‌رود. یک مجموعه ثابت از
$K$
مشتری وجود دارد که هر کدام یک مجموعه داده محلی ثابت دارند. در ابتدای هر دوره، یک کسر تصادفی
$C$
از مشتری‌ها انتخاب می‌شوند و سرور وضعیت فعلی پارامترهای مدل جهانی را به هر یک از این مشتری‌ها ارسال می‌کند. هر مشتری انتخاب ‌شده سپس بر اساس وضعیت جهانی و مجموعه داده محلی خود محاسبات محلی را انجام می‌دهد و یک به‌روزرسانی به سرور ارسال می‌کند. سپس سرور این به‌روزرسانی‌ها را به وضعیت جهانی خود اعمال می‌کند و این فرآیند تکرار می‌شود
\cite{mcmahan2017communication}.

در حالی که ما بر اهداف شبکه عصبی غیرمحدب
\LTRfootnote{Non-Convex}
تمرکز داریم، الگوریتمی که بررسی می‌کنیم قابل اعمال به هر هدف مجموع-متناهی
\LTRfootnote{Finite-Sum}
به صورت زیر است.
\begin{equation}
\min _{w \in \mathbb{R}^d} f(w) \quad \text { where } \quad f(w) \stackrel{\text { def }}{=} \frac{1}{n} \sum_{i=1}^n f_i(w)
\label{eq_base}
\end{equation}
برای یک مسئله یادگیری ماشین، معمولاً
$f_i(w)=\ell\left(x_i, y_i ; w\right)$
در نظر گرفته می‌شود، به این معنی که این تابع نشان‌دهنده‌ی خطای پیش‌بینی بر روی نمونه
$(x_i, y_i)$
با استفاده از پارامترهای مدل
$w$
است. فرض می‌کنیم که داده‌ها بین
$K$
مشتری تقسیم شده‌اند، که در آن
$\mathcal{P}_k$
مجموعه‌ای از نقاط داده مربوط به مشتری
$k$
است و
$n_k=\left|\mathcal{P}_k\right|$
تعداد این نقاط داده را نشان می‌دهد. بنابراین، می‌توانیم فرمول
\ref{eq_base}
را به صورت زیر بازنویسی کنیم:
\begin{equation}
f(w)=\sum_{k=1}^K \frac{n_k}{n} F_k(w) \quad \text { where } \quad F_k(w)=\frac{1}{n_k} \sum_{i \in \mathcal{P}_k} f_i(w)
\end{equation}

اگر مجموعه
$\mathcal{P}_k$
با توزیع یکنواخت تصادفی از مثال‌های آموزشی بین مشتری‌ها تشکیل شده باشد، در آن صورت
$\mathbb{E}_{\mathcal{P}_k}\left[F_k(w)\right]=f(w)$ 
خواهد بود، که در اینجا امید ریاضی بر روی مجموعه مثال‌های اختصاص داده شده به یک مشتری ثابت گرفته می‌شود. این همان فرض
\lr{IID}
(استقلال و توزیع یکسان)
است که عموماً توسط الگوریتم‌های بهینه‌سازی توزیع‌شده استفاده می‌شود، در این‌جا ما حالتی را که این فرض برقرار نیست (یعنی
$F_k$
می‌تواند تقریباً به هر میزانی از
$f$
فاصله داشته باشد) به عنوان حالت
\lr{Non-IID}
(غیرمستقل و غیریکنواخت)
می‌شناسیم
\cite{mcmahan2017communication}.


\section{رویکردهای کلی و پایه‌ای در حل چالش‌ها}
روش‌های بهینه‌سازی توزیع‌شده معمولاً برای حل مسائل بهینه‌سازی در سیستم‌هایی با شبکه‌های محاسباتی بزرگ و توزیع‌شده استفاده می‌شوند. این روش‌ها بر مبنای تقسیم مسئله بهینه‌سازی به زیرمسائل کوچک‌تر و حل آن‌ها در گره‌های مختلف شبکه استوارند. در این روش‌ها، اغلب فرض می‌شود که داده‌ها به صورت همگن و یکپارچه در سراسر شبکه توزیع شده‌اند و گره‌ها می‌توانند به راحتی با یکدیگر ارتباط برقرار کنند.

فرضیات مطرح شده در یادگیری فدرال به ندرت برقرار است، زیرا در یادگیری فدرال داده‌ها به صورت محلی و ناهمگن در دستگاه‌های مختلف قرار دارند و ارتباطات بین دستگاه‌ها ممکن است محدود و نامنظم باشد. بنابراین روش‌ها و رویکردهای لازم جهت حل این چالش‌ها متفاوت از مسائل بهینه‌سازی توزیع شده هستند. حال سعی می‌کنیم دو رویکرد پایه‌ای برای مسائل یادگیری فدرال را مطرح نماییم.

\subsection{به‌روزرسانی محلی و میانگین‌گیری در سرور}
یکی از روش‌های اصلی و پرکاربرد در یادگیری فدرال روش میانگین‌گیری فدرال%
\LTRfootnote{Federated Averaging}
\lr{(FedAvg)}
است که توسط محققان گوگل در سال 2017 معرفی شد. این الگوریتم به منظور بهینه‌سازی مدل‌های یادگیری ماشین در یک محیط توزیع‌شده طراحی شده است، جایی که داده‌ها به صورت محلی در دستگاه‌های کاربران باقی می‌مانند و تنها به‌روزرسانی‌های مدل به اشتراک گذاشته می‌شوند. رویکرد اصلی
\lr{FedAvg}
بر مبنای ترکیب به‌روزرسانی‌های محلی از دستگاه‌های مختلف به یک مدل جهانی استوار است.

یکی از مزایای اصلی
\lr{FedAvg}
این است که به طور موثری با چالش ناهمگنی داده‌ها مقابله می‌کند. در یادگیری فدرال، داده‌های موجود در دستگاه‌های مختلف ممکن است توزیع‌های متفاوتی داشته باشند. این ناهمگنی می‌تواند به دلیل تفاوت در رفتار کاربران یا حتی محیط‌های مختلف جمع‌آوری داده باشد. میانگین‌گیری وزنی در
\lr{FedAvg}
به مدل کمک می‌کند تا به‌روزرسانی‌های مختلف را به گونه‌ای ترکیب کند که این ناهمگنی‌ها را در نظر بگیرد. به عبارت دیگر، اگر یک دستگاه داده‌های بیشتری داشته باشد، تأثیر بیشتری بر مدل نهایی خواهد داشت. این رویکرد باعث می‌شود که مدل فدرال به تعادل بهتری در یادگیری از داده‌های ناهمگن برسد و کارایی بالاتری داشته باشد. این ویژگی به خصوص در کاربردهایی که کاربران متنوع و داده‌های متنوعی دارند، بسیار مفید است و می‌تواند به بهبود عملکرد مدل در شرایط واقعی کمک کند.

علاوه بر این،
\lr{FedAvg}
به کاهش نیاز به ارتباطات مکرر بین دستگاه‌ها و سرور مرکزی کمک می‌کند. در بسیاری از روش‌های بهینه‌سازی توزیع‌شده، نیاز است که دستگاه‌ها به طور مکرر با سرور مرکزی ارتباط برقرار کنند تا به‌روزرسانی‌های خود را ارسال کنند. اما در
\lr{FedAvg}
دستگاه‌ها می‌توانند چندین مرحله از بهینه‌سازی را به صورت محلی انجام دهند و سپس تنها به‌روزرسانی نهایی را ارسال کنند. این کاهش در نیاز به ارتباطات نه تنها باعث کاهش پهنای باند مورد نیاز می‌شود، بلکه به حفظ حریم خصوصی کاربران نیز کمک می‌کند، زیرا داده‌ها هرگز از دستگاه‌های محلی خارج نمی‌شوند. بررسی‌ها نشان داده‌اند که متناسب با اندازه داده‌ها پس از رسیدن به تعداد معینی از گره‌ها، اضافه کردن گره‌های بیشتر تأثیری در کاهش هزینه‌های ارتباطی نخواهد داشت. در چنین شرایطی، تمرکز بر افزایش توان محاسباتی محلی یا تعداد مراحل آموزش محلی می‌تواند موجب تسریع فرایند آموزش شود
\cite{mcmahan2017communication}.

موفقیت‌های اخیر در کاربردهای یادگیری عمیق تقریباً به‌طور انحصاری به استفاده از انواع الگوریتم نزول گرادیان تصادفی%
\LTRfootnote{Stochastic Gradient Descent}
\lr{(SGD)}
برای بهینه‌سازی متکی بوده‌اند. در واقع، بسیاری از پیشرفت‌ها به تنظیم مدل و بهینه‌سازی تابع خطا با روش‌های ساده گرادیان مربوط می‌شود. بنابراین، طبیعی است که ما الگوریتم‌های بهینه‌سازی فدرال را با شروع از
\lr{SGD}
بسازیم.

الگوریتم
\lr{SGD}
می‌تواند به سادگی در بهینه‌سازی فدرال استفاده شود، به این صورت که در هر دور ارتباط، گرادیان‌ها بر اساس داده‌های یک مشتری تصادفی انتخاب شده، محاسبه ‌شوند. این رویکرد از نظر محاسباتی کارآمد است، اما نیازمند تعداد بسیار زیادی از دورهای آموزش برای تولید مدل‌های خوب است.
برای مثال حتی با استفاده از رویکرد پیشرفته‌ای مانند نرمال‌سازی دسته‌ای%
\LTRfootnote{Batch Normalization}%
، برای آموزش دیتاست معروف
\lr{MNIST}
(دیتاستی جهت دسته‌بندی اعداد دستنویس بین صفر تا نه)
با دسته‌های کوچکی به اندازه 60 به 50000 دور آموزش جهت رسیدن به مدل مطلوب نیاز می‌باشد
\cite{ioffe2015batch}.

در تنظیمات فدرال، مشارکت تعداد زیادتری از مشتریان هزینه‌ای آنچنان بیشتری در زمان واقعی ندارد زیرا همه کاربران می‌توانند به صورت همزمان اقدام به آموزش مدل محلی کنند، بنابراین برای خط مبنای خود از
\lr{SGD}
همزمان با دسته‌های بزرگ استفاده می‌کنیم. برای اعمال این رویکرد در تنظیمات فدرال، ما در هر دور یک کسر
$C$
از مشتریان را انتخاب می‌کنیم و گرادیان خطا روی تمام داده‌های نگهداری شده توسط این مشتریان را محاسبه می‌کنیم. بنابراین
$C$
اندازه دسته‌ کلی را کنترل می‌کند، به‌طوری که
$C = 1$
معادل با نزول گرادیان یک دسته کامل است. حال این الگوریتم خط مبنا را
\lr{FederatedSGD}
یا
\lr{FedSGD}
می‌نامیم.

یک پیاده‌سازی معمول از
\lr{FedSGD}
با
$C = 1$
و نرخ یادگیری ثابت
$\eta$
به این صورت است که هر گره
$k$%
، گرادیان
$g_k=\nabla F_k\left(w_t\right)$
که میانگین گرادیان روی داده‌های محلی در مدل فعلی
$w_t$
است را محاسبه می‌کند و سرور مرکزی این گرادیان‌ها را جمع‌آوری کرده و به‌روزرسانی
$w_{t+1} \leftarrow w_t-\eta \sum_{k=1}^K \frac{n_k}{n} g_k$
را انجام می‌دهد، در حالی که
$\sum_{k=1}^K \frac{n_k}{n} g_k=\nabla f\left(w_t\right)$
خواهد بود. یک به‌روزرسانی معادل به این صورت است که برای هر گره عبارت
$\forall k, w_{t+1}^k \leftarrow w_t-\eta g_k$
محاسبه و سپس
$w_{t+1} \leftarrow \sum_{k=1}^K \frac{n_k}{n} w_{t+1}^k$
انجام شود.

در نتیجه، هر گره به صورت محلی یک گام گرادیان نزولی را روی مدل فعلی با استفاده از داده‌های محلی خود طی می‌کند و سپس سرور میانگین وزنی مدل‌های حاصل را محاسبه می‌کند. وقتی که الگوریتم به این صورت نوشته شود، می‌توانیم با تکرار به‌روزرسانی محلی
$w^k \leftarrow w^k-\eta \nabla F_k\left(w^k\right)$%
، چندین بار قبل از مرحله میانگین‌گیری، محاسبات بیشتری به هر گره اضافه کنیم. در نهایت این رویکرد جدید را
\lr{FederatedAveraging}
\lr{(FedAvg)}
می‌نامیم.

میزان محاسبات توسط سه پارامتر کلیدی کنترل می‌شود:
$C$%
، کسر گره‌هایی که در هر مرحله محاسبات انجام می‌دهند؛
$E$%
، تعداد مراحل آموزشی که هر گره در هر دور روی مجموعه داده محلی خود انجام می‌دهد؛ و
$B$%
، اندازه دسته محلی که برای به‌روزرسانی‌های هر گره استفاده می‌شود. در اینجا
$B = \infty$
را می‌نویسیم تا نشان دهیم که کل مجموعه داده محلی به عنوان یک دسته واحد در نظر گرفته می‌شود. بنابراین، به عنوان یک نمونه از این الگوریتم گسترده شده جدید، می‌توانیم
$B = \infty$
و
$E = 1$
را انتخاب کنیم که در این حالت دقیقاً با
\lr{FedSGD}
برابر خواهد شد. همچنین برای یک گره با
$n_k$
نمونه محلی، تعداد به‌روزرسانی‌های محلی در هر دور با
$u_k=E \frac{n_k}{B}$
نمایش داده می‌شود
\cite{mcmahan2017communication}.



\subsection{
بهینه‌سازی
\lr{\texttt{\fontspec{Times New Roman} FedProx}}
}
روش
\lr{FedProx}
به بررسی چالش‌های یادگیری فدرال در بسترهای ناهمگن می‌پردازد. این روش با ایجاد تغییرات جزئی در روش موجود
\lr{FedAvg}%
، به بهبود پایداری و دقت در شبکه‌های ناهمگن کمک می‌کند. این تغییرات شامل اضافه کردن یک عبارت نزدیک مبدا%
\LTRfootnote{Proximal Term}
به تابع هدف است که به صورت اصولی به سرور کمک می‌کند تا ناهمگنی را مدیریت کند.

فرمول هدف
\lr{FedProx}
به صورت زیر تعریف می‌شود:
\begin{equation}
\min_{w} f(w) = \min_{w} \sum_{k=1}^{K} \frac{n_k}{n} \left( F_k(w) + \frac{\mu}{2} \|w^t - w_k^t\|^2 \right)
\label{eq_FedProx}
\end{equation}

در فرمول
\ref{eq_FedProx}
بخش
$\frac{\mu}{2} \|w^t - w_k^t\|^2$%
، همان عبارت نزدیک مبدا است که به تابع هدف اضافه شده است. همچنین
$\mu$%
، یک پارامتر تنظیم برای این عبارت به حساب می‌آید و در نهایت
$w_k^t$
وزن‌های مدل محلی دستگاه
$k$
در تکرار
$t$
است.

حال با توجه به فرمول
\ref{eq_FedProx}%
، به‌روزرسانی وزن‌ها به شکل زیر تغییر پیدا خواهد کرد و بخش
$\mu (w^t - w_k^t)$%
، گرادیان عبارت نزدیک مبدا است.
\begin{equation*}
w^{t+1} = w^t - \eta (\nabla F_k(w^t) + \mu (w^t - w_k^t))
\end{equation*}

بنابراین، به‌روزرسانی‌های محلی در هر گام با به‌روزرسانی سراسری مرحله قبل مرتبط هستند. عبارت نزدیک مبدا به عنوان یک مکانیزم منظم‌کننده%
\LTRfootnote{Regularization}
عمل می‌کند که تفاوت‌های بین وزن‌های جهانی
$w$
و وزن‌های محلی
$w_k^t$
را کاهش می‌دهد. این ترم به کاهش تاثیرات منفی ناهمگنی سیستم‌ها و داده‌ها کمک می‌کند و باعث پایداری بیشتر در فرآیند همگرایی می‌شود
\cite{li2020federatedheteroneneous}.

