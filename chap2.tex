% Chapter 2
\chapter{مفاهیم پایه در یادگیری فدرال}

\section{مقدمه}
در جستجوی راه‌حل‌هایی برای یادگیری فدرال، لازم است به یک واقعیت مهم توجه کنیم که توزیع فرآیند آموزش بین افراد یا دستگاه‌های مختلف ممکن است به تداخل‌ها و مشکلاتی منجر شود. اگر این چالش‌ها را پیش از شروع فرآیند مدل‌سازی به‌خوبی در نظر نگیریم و راه‌حل‌های مشخصی برای آنها ارائه ندهیم، مدلی که در نهایت تولید می‌شود قطعاً با مشکلاتی از جمله دقت و کارایی مواجه خواهد شد. این مسئله، یکی از بزرگترین معظلاتی است که در مسیر یادگیری فدرال با آن روبرو می‌شویم و برای حل آن، نیازمند توجه دقیق و استفاده از روش‌های مختلف و نوآورانه هستیم.

در این فصل ابتدا چالش‌های موجود در یادگیری فدرال را رصد خواهیم کرد و سپس نگاه مقالات را در هر یک از آن‌ها به صورت کلی بررسی می‌کنیم. در ادامه، بیان ریاضی یادگیری فدرال را توضیح خواهیم داد و در نهایت به رویکردهای کلی و پایه‌ای در حل چالش‌ها اشاره خواهیم داشت.

\section{چالش‌های موجود در یادگیری فدرال}
با وجود مزیت‌های بسیار زیاد نسبت به روش‌های سنتی یادگیری ماشین، یادگیری فدرال به دلیل ساختار شبکه یادگیری با چالش‌های گوناگونی روبرو است. چالش‌های اصلی یادگیری فدرال عبارتند از:


\subsection{تبادل داده بین سرور و کاربران}
تبادل داده بین سرور و کاربران به دلیل مشکلات پهنای باند و ارتباطات شبکه‌ای اصولا کار پر هزینه‌ای می‌باشد. یکی از دلایل اصلی پرهزینه بودن این ارتباطات، حجم بالای داده‌هایی است که باید بین دستگاه‌های کاربری و سرور منتقل شوند.
معمولاً مشکلات ارتباطی به انتقال‌های بسیار زیاد به‌روزرسانی‌های گرادیان بین گره‌های محاسباتی نسبت داده می‌شوند. با افزایش تعداد پارامترها در مدل‌های پیشرفته، اندازه گرادیان‌ها نیز به طور متناسب بزرگ می‌شود
\cite{wang2018atomo}.

با این حال، تعداد زیادی از دستگاه‌های کاربر نهایی وجود دارند که در فرآیند آموزش مدل‌ها شرکت می‌کنند، که این موضوع می‌تواند هزینه‌های ارتباطات را به شدت افزایش دهد. علاوه بر این، در بسیاری از مواقع، همه دستگاه‌ها در هر چرخه از فرآیند آموزش شرکت نمی‌کنند، که این نیز به افزایش هزینه‌ها و پیچیدگی‌های مرتبط با انتقال داده‌ها منجر می‌شود.


\subsection{ناهمگنی‌های سیستمی}
در دنیای یادگیری فدرال، دستگاه‌ها از نظر حافظه، توان محاسباتی و ارتباطات بسیار با یکدیگر متفاوت هستند. این تفاوت‌ها ممکن است از اختلافاتی مانند تفاوت در پردازنده، نوع حافظه، نوع اتصال شبکه و نیاز به انرژی ناشی شود. محدودیت‌های موجود در شبکه و سیستمی می‌توانند باعث ایجاد وضعیت‌هایی شوند که برخی از دستگاه‌ها در یک زمان معین در دسترس نباشند. برای مثال، اگر تعداد زیادی دستگاه همزمان درخواست ارسال داشته باشند، ممکن است برخی از آن‌ها به دلیل پهنای باند محدود یا محدودیت‌های سخت‌افزاری، قادر به ارسال درخواست نشوند. همچنین، ممکن است یک دستگاه فعال، به دلیل مشکلاتی مانند اختلالات در شبکه یا مصرف اضافی انرژی، از فرآیند یادگیری خارج شود.

این ویژگی‌های سیستمی، جزء اصلی چالش‌های یادگیری فدرال هستند و موجب افزایش تاخیر و اشکالات در سیستم می‌شوند. بنابراین، به منظور حل این مشکلات، روش‌های یادگیری فدرال باید قادر باشند تعداد دقیقی از دستگاه‌هایی که در فرآیند شرکت می‌کنند را پیش‌بینی کنند، همچنین باید در برابر دستگاه‌هایی که در حین عملیات با مشکل روبه‌رو شده‌اند مقاومت مناسبی داشته باشند
\cite{li2020federated}.


\subsection{ناهمگنی‌های آماری}
 طریقه تولید و جمع‌آوری داده‌ها بین دستگاه‌ها به شکل گوناگونی انجام می‌شود. این مجموعه داده‌ها اغلب مستقل از یکدیگر نیستند و ارتباطات و اتصالات میان آن‌ها وجود دارد. این الگوی تولید داده‌ها، با فرض استقلال و توزیع یکنواخت داده%
 \LTRfootnote{Independent and Identically Distributed}
  \lr{(IID)}
  در مسائل بهینه‌سازی متضاد است، که باعث ایجاد پیچیدگی در مدل‌سازی، تجزیه و تحلیل نظری و ارزیابی عملکرد راه‌حل‌ها می‌شود. در نتیجه، هرچند هدف نهایی یادگیری یک مدل سراسری است، اما روش‌های جایگزین مانند آموزش همزمان مدل‌های محلی جداگانه از طریق یادگیری چندوظیفه‌ای%
  \LTRfootnote{Multi-Tasking}
  و فرایادگیری%
   \LTRfootnote{Meta Learning}%
  ، به عنوان گزینه‌های جایگزین مطرح شده‌اند
   \cite{li2020federated}.
   
\subsection{حریم شخصی}
یکی از چالش‌های اساسی در یادگیری فدرال، حفظ حریم شخصی است که در این روش، داده‌های حساس و شخصی در اختیار بخش‌های مختلفی از شبکه قرار می‌گیرند. در این روش، دستگاه‌های محلی اطلاعاتی از کاربران جمع‌آوری و به سرور ارسال می‌کنند تا مدل‌های یادگیری مشترک را به‌روزرسانی کنند. این ارتباطات می‌توانند حاوی اطلاعات حساسی باشند که می‌توانند به راحتی به شناسایی فرد یا فرآیندهای حیاتی او منجر شوند.

یکی از مشکلات اساسی در اینجا این است که حتی با استفاده از روش‌های رمزنگاری و حفظ امنیت، اطلاعات معینی همچنان ممکن است به سرور ارسال شود که احتمالاً می‌تواند حریم شخصی را نقض کند. به‌طور خاص، اگر داده‌های حساس بدون رمزنگاری به سرور ارسال شوند یا اگر حتی اطلاعاتی که قابلیت شناسایی فرد را دارند به صورت رمزگذاری نشده ارسال شوند، حریم شخصی کاربران مورد تهدید قرار می‌گیرد.


\section{نگاه مقالات مرتبط به چالش‌های موجود}

\subsection{تبادل داده}
با استفاده از فشرده‌سازی داده‌ها، می‌توان هزینه‌های ارتباطی را به طور قابل توجهی کاهش داد. دو روش جهت مدیریت هزینه‌های بالای ارتباطات در فرایند یادگیری فدرال مورد بررسی قرار گرفته است. این روش‌ها به فشرده‌سازی داده‌هایی که از دستگاه‌های کاربری به سرور مرکزی ارسال می‌شوند متمرکز شده‌اند. این فشرده‌سازی اطلاعات ارسالی به گونه‌ای است که حجم داده‌های ارسالی کم شده و در نتیجه، هزینه‌های مربوط به ارتباطات نیز کاهش یابد
\cite{konevcny2016federated}.

در روشی به نام
\lr{PCFL}%
\LTRfootnote{Privacy Communication efficient Federated Learning}
که یک رویکرد حفظ حریم خصوصی و البته بسیار کارآمد از نظر ارتباطی می‌باشد، شامل سه جزء کلیدی است که به ترتیب از فشرده‌سازی دوطرفه، فشرده‌سازی مکانی گرادیان‌ها و یک پروتکل حفظ حریم خصوصی که خود از تقسیم راز%
\LTRfootnote{Secret Sharing}
 و رمزنگاری همگام%
 \LTRfootnote{Homomorphic Encryption}
  برای محافظت از حریم خصوصی داده‌ها استفاده می‌کند، بهره گرفته است
  \cite{fang2021privacy}.


\subsection{ناهمگنی سیستمی و آماری}
برای مقابله با ناهمگنی سیستمی و آماری، روش‌هایی مانند تعادل در به‌روزرسانی مدل مطرح شده است. در این روش، وزن‌دهی به نمونه‌ها بر اساس میزان نیاز به آموزش در هر دستگاه صورت می‌گیرد. این کار باعث می‌شود که دستگاه‌های با حجم داده کمتر، وزن بیشتری در به‌روزرسانی مدل داشته باشند
\cite{konevcny2015federated}.
در رویکرد دیگری به نام یادگیری فعال، دستگاه‌هایی که داده‌های خود را به سرور ارسال می‌کنند، فعالیت خود را به نحوی تنظیم می‌کنند که مدل از داده‌های مهم‌تر و کمتر دیده شده بیشتر یاد می‌گیرد. این روش می‌تواند به تعادل در آموزش مدل کمک کند و از ناهمگنی سیستمی جلوگیری کند
\cite{konevcny2016federated}.

یک روش دیگر برای حل مشکل ناهمگنی سیستمی و آماری در یادگیری فدرال استفاده از رویکرد ترکیبی یا ترکیب روش‌های یادگیری محلی است. در این رویکرد، به جای استفاده از یک الگوریتم یادگیری مشترک برای تمام دستگاه‌ها، از چندین الگوریتم یادگیری محلی با تنوع مدل‌ها و تنظیمات مختلف استفاده می‌شود. سپس، اطلاعات مدل‌های محلی روی سرور یا گره مرکزی جمع‌آوری می‌شود و با استفاده از ترکیب این اطلاعات، یک مدل یادگیری مشترک بروزرسانی خواهد شد
\cite{konevcny2015federated}.


\subsection{حریم شخصی}
در روش حفظ حریم خصوصی تفاضلی%
\LTRfootnote{Differential Privacy}
با افزودن نویز به نتایج محاسبات یا به داده‌های ورودی، اطمینان حاصل می‌کند که حضور یا عدم حضور یک نمونه داده خاص در مجموعه داده‌ها، تأثیر قابل توجهی بر خروجی محاسبات نداشته باشد. این روش به ویژه برای حفظ حریم خصوصی در یادگیری فدرال مفید است زیرا از افشای اطلاعات حساس از طریق پارامترهای مدل جلوگیری می‌کند
\cite{hasan2023security}.

رویکرد رمزنگاری همگام امکان محاسبه روی داده‌های رمزنگاری شده را بدون نیاز به رمزگشایی آن‌ها فراهم می‌کند. این تکنیک به ویژه در یادگیری فدرال برای حفظ حریم خصوصی داده‌ها در حین انجام محاسبات مفید است زیرا نیاز به تغییر ماهیت داده نبوده و چون جابجایی در یادگیری فدرال بسیار زیاد رخ می‌دهد، این روش بسیار کارا خواهد بود
\cite{yin2021comprehensive}.



\section{بیان ریاضی یادگیری فدرال}
برای ورود به مباحث ریاضی پایه در یادگیری فدرال، ابتدا باید به تعریف دقیق مسئله بهینه‌سازی مرکزی بپردازیم که در این حوزه مطرح می‌شود. در یادگیری فدرال، هدف اصلی یافتن مجموعه‌ای از پارامترهای مدل است که عملکرد کلی مدل را بر روی داده‌های توزیع‌شده بین تعداد زیادی دستگاه بهینه کند. هر دستگاه دارای داده‌های محلی است و یک تابع هزینه محلی بر اساس این داده‌ها برای آن دستگاه تعریف می‌شود. مسئله بهینه‌سازی کلی در یادگیری فدرال به دنبال کمینه کردن مجموع وزنی این توابع هزینه محلی است تا یک مدل جامع و یکپارچه حاصل شود.

ما یک طرح به‌روزرسانی همزمان را فرض می‌کنیم که به صورت دوره‌های ارتباطی پیش می‌رود. یک مجموعه ثابت از
$K$
مشتری وجود دارد که هر کدام یک مجموعه داده محلی ثابت دارند. در ابتدای هر دوره، یک کسر تصادفی
$C$
از مشتری‌ها انتخاب می‌شوند و سرور وضعیت فعلی پارامترهای مدل جهانی را به هر یک از این مشتری‌ها ارسال می‌کند. هر مشتری انتخاب ‌شده سپس بر اساس وضعیت جهانی و مجموعه داده محلی خود محاسبات محلی را انجام می‌دهد و یک به‌روزرسانی به سرور ارسال می‌کند. سپس سرور این به‌روزرسانی‌ها را به وضعیت جهانی خود اعمال می‌کند و این فرآیند تکرار می‌شود
\cite{mcmahan2017communication}.

در حالی که ما بر اهداف شبکه عصبی غیرمحدب
\LTRfootnote{Non-Convex}
تمرکز داریم، الگوریتمی که بررسی می‌کنیم قابل اعمال به هر هدف مجموع-متناهی
\LTRfootnote{Finite-Sum}
به صورت زیر است.
\begin{equation}
\min _{w \in \mathbb{R}^d} f(w) \quad \text { where } \quad f(w) \stackrel{\text { def }}{=} \frac{1}{n} \sum_{i=1}^n f_i(w)
\label{eq_base}
\end{equation}
برای یک مسئله یادگیری ماشین، معمولاً
$f_i(w)=\ell\left(x_i, y_i ; w\right)$
در نظر گرفته می‌شود، به این معنی که این تابع نشان‌دهنده‌ی خطای پیش‌بینی بر روی نمونه
$(x_i, y_i)$
با استفاده از پارامترهای مدل
$w$
است. فرض می‌کنیم که داده‌ها بین
$K$
مشتری تقسیم شده‌اند، که در آن
$\mathcal{P}_k$
مجموعه‌ای از نقاط داده مربوط به مشتری
$k$
است و
$n_k=\left|\mathcal{P}_k\right|$
تعداد این نقاط داده را نشان می‌دهد. بنابراین، می‌توانیم فرمول
\ref{eq_base}
را به صورت زیر بازنویسی کنیم:
\begin{equation}
f(w)=\sum_{k=1}^K \frac{n_k}{n} F_k(w) \quad \text { where } \quad F_k(w)=\frac{1}{n_k} \sum_{i \in \mathcal{P}_k} f_i(w)
\end{equation}

اگر مجموعه
$\mathcal{P}_k$
با توزیع یکنواخت تصادفی از مثال‌های آموزشی بین مشتری‌ها تشکیل شده باشد، در آن صورت
$\mathbb{E}_{\mathcal{P}_k}\left[F_k(w)\right]=f(w)$ 
خواهد بود، که در اینجا امید ریاضی بر روی مجموعه مثال‌های اختصاص داده شده به یک مشتری ثابت گرفته می‌شود. این همان فرض
\lr{IID}
(استقلال و توزیع یکسان)
است که عموماً توسط الگوریتم‌های بهینه‌سازی توزیع‌شده استفاده می‌شود، در این‌جا ما حالتی را که این فرض برقرار نیست (یعنی
$F_k$
می‌تواند تقریباً به هر میزانی از
$f$
فاصله داشته باشد) به عنوان حالت
\lr{Non-IID}
(غیرمستقل و غیریکنواخت)
می‌شناسیم
\cite{mcmahan2017communication}.


\section{رویکردهای کلی و پایه‌ای در حل چالش‌ها}
روش‌های بهینه‌سازی توزیع‌شده معمولاً برای حل مسائل بهینه‌سازی در سیستم‌هایی با شبکه‌های محاسباتی بزرگ و توزیع‌شده استفاده می‌شوند. این روش‌ها بر مبنای تقسیم مسئله بهینه‌سازی به زیرمسائل کوچک‌تر و حل آن‌ها در گره‌های مختلف شبکه استوارند. در این روش‌ها، اغلب فرض می‌شود که داده‌ها به صورت همگن و یکپارچه در سراسر شبکه توزیع شده‌اند و گره‌ها می‌توانند به راحتی با یکدیگر ارتباط برقرار کنند.

فرضیات مطرح شده در یادگیری فدرال به ندرت برقرار است، زیرا در یادگیری فدرال داده‌ها به صورت محلی و ناهمگن در دستگاه‌های مختلف قرار دارند و ارتباطات بین دستگاه‌ها ممکن است محدود و نامنظم باشد. بنابراین روش‌ها و رویکردهای لازم جهت حل این چالش‌ها متفاوت از مسائل بهینه‌سازی توزیع شده هستند. حال سعی می‌کنیم دو رویکرد پایه‌ای برای مسائل یادگیری فدرال را مطرح نماییم.

\subsection{به‌روزرسانی محلی و میانگین‌گیری در سرور}
یکی از روش‌های اصلی و پرکاربرد در یادگیری فدرال روش میانگین‌گیری فدرال%
\LTRfootnote{Federated Averaging}
\lr{(FedAvg)}
است که توسط محققان گوگل در سال 2017 معرفی شد. این الگوریتم به منظور بهینه‌سازی مدل‌های یادگیری ماشین در یک محیط توزیع‌شده طراحی شده است، جایی که داده‌ها به صورت محلی در دستگاه‌های کاربران باقی می‌مانند و تنها به‌روزرسانی‌های مدل به اشتراک گذاشته می‌شوند. رویکرد اصلی
\lr{FedAvg}
بر مبنای ترکیب به‌روزرسانی‌های محلی از دستگاه‌های مختلف به یک مدل جهانی استوار است.

یکی از مزایای اصلی
\lr{FedAvg}
این است که به طور موثری با چالش ناهمگنی داده‌ها مقابله می‌کند. در یادگیری فدرال، داده‌های موجود در دستگاه‌های مختلف ممکن است توزیع‌های متفاوتی داشته باشند. این ناهمگنی می‌تواند به دلیل تفاوت در رفتار کاربران یا حتی محیط‌های مختلف جمع‌آوری داده باشد. میانگین‌گیری وزنی در
\lr{FedAvg}
به مدل کمک می‌کند تا به‌روزرسانی‌های مختلف را به گونه‌ای ترکیب کند که این ناهمگنی‌ها را در نظر بگیرد. به عبارت دیگر، اگر یک دستگاه داده‌های بیشتری داشته باشد، تأثیر بیشتری بر مدل نهایی خواهد داشت. این رویکرد باعث می‌شود که مدل فدرال به تعادل بهتری در یادگیری از داده‌های ناهمگن برسد و کارایی بالاتری داشته باشد. این ویژگی به خصوص در کاربردهایی که کاربران متنوع و داده‌های متنوعی دارند، بسیار مفید است و می‌تواند به بهبود عملکرد مدل در شرایط واقعی کمک کند.

علاوه بر این،
\lr{FedAvg}
به کاهش نیاز به ارتباطات مکرر بین دستگاه‌ها و سرور مرکزی کمک می‌کند. در بسیاری از روش‌های بهینه‌سازی توزیع‌شده، نیاز است که دستگاه‌ها به طور مکرر با سرور مرکزی ارتباط برقرار کنند تا به‌روزرسانی‌های خود را ارسال کنند. اما در
\lr{FedAvg}
دستگاه‌ها می‌توانند چندین مرحله از بهینه‌سازی را به صورت محلی انجام دهند و سپس تنها به‌روزرسانی نهایی را ارسال کنند. این کاهش در نیاز به ارتباطات نه تنها باعث کاهش پهنای باند مورد نیاز می‌شود، بلکه به حفظ حریم خصوصی کاربران نیز کمک می‌کند، زیرا داده‌ها هرگز از دستگاه‌های محلی خارج نمی‌شوند. بررسی‌ها نشان داده‌اند که متناسب با اندازه داده‌ها پس از رسیدن به تعداد معینی از گره‌ها، اضافه کردن گره‌های بیشتر تأثیری در کاهش هزینه‌های ارتباطی نخواهد داشت. در چنین شرایطی، تمرکز بر افزایش توان محاسباتی محلی یا تعداد مراحل آموزش محلی می‌تواند موجب تسریع فرایند آموزش شود
\cite{mcmahan2017communication}.

موفقیت‌های اخیر در کاربردهای یادگیری عمیق تقریباً به‌طور انحصاری به استفاده از انواع الگوریتم نزول گرادیان تصادفی%
\LTRfootnote{Stochastic Gradient Descent}
\lr{(SGD)}
برای بهینه‌سازی متکی بوده‌اند. در واقع، بسیاری از پیشرفت‌ها به تنظیم مدل و بهینه‌سازی تابع خطا با روش‌های ساده گرادیان مربوط می‌شود. بنابراین، طبیعی است که ما الگوریتم‌های بهینه‌سازی فدرال را با شروع از
\lr{SGD}
بسازیم.

الگوریتم
\lr{SGD}
می‌تواند به سادگی در بهینه‌سازی فدرال استفاده شود، به این صورت که در هر دور ارتباط، گرادیان‌ها بر اساس داده‌های یک مشتری تصادفی انتخاب شده، محاسبه ‌شوند. این رویکرد از نظر محاسباتی کارآمد است، اما نیازمند تعداد بسیار زیادی از دورهای آموزش برای تولید مدل‌های خوب است.
برای مثال حتی با استفاده از رویکرد پیشرفته‌ای مانند نرمال‌سازی دسته‌ای%
\LTRfootnote{Batch Normalization}%
، برای آموزش دیتاست معروف
\lr{MNIST}
(دیتاستی جهت دسته‌بندی اعداد دستنویس بین صفر تا نه)
با دسته‌های کوچکی به اندازه 60 به 50000 دور آموزش جهت رسیدن به مدل مطلوب نیاز می‌باشد
\cite{ioffe2015batch}.

در تنظیمات فدرال، مشارکت تعداد زیادتری از مشتریان هزینه‌ای آنچنان بیشتری در زمان واقعی ندارد زیرا همه کاربران می‌توانند به صورت همزمان اقدام به آموزش مدل محلی کنند، بنابراین برای خط مبنای خود از
\lr{SGD}
همزمان با دسته‌های بزرگ استفاده می‌کنیم. برای اعمال این رویکرد در تنظیمات فدرال، ما در هر دور یک کسر
$C$
از مشتریان را انتخاب می‌کنیم و گرادیان خطا روی تمام داده‌های نگهداری شده توسط این مشتریان را محاسبه می‌کنیم. بنابراین
$C$
اندازه دسته‌ کلی را کنترل می‌کند، به‌طوری که
$C = 1$
معادل با نزول گرادیان یک دسته کامل است. حال این الگوریتم خط مبنا را
\lr{FederatedSGD}
یا
\lr{FedSGD}
می‌نامیم.

یک پیاده‌سازی معمول از
\lr{FedSGD}
با
$C = 1$
و نرخ یادگیری ثابت
$\eta$
به این صورت است که هر گره
$k$%
، گرادیان
$g_k=\nabla F_k\left(w_t\right)$
که میانگین گرادیان روی داده‌های محلی در مدل فعلی
$w_t$
است را محاسبه می‌کند و سرور مرکزی این گرادیان‌ها را جمع‌آوری کرده و به‌روزرسانی
$w_{t+1} \leftarrow w_t-\eta \sum_{k=1}^K \frac{n_k}{n} g_k$
را انجام می‌دهد، در حالی که
$\sum_{k=1}^K \frac{n_k}{n} g_k=\nabla f\left(w_t\right)$
خواهد بود. یک به‌روزرسانی معادل به این صورت است که برای هر گره عبارت
$\forall k, w_{t+1}^k \leftarrow w_t-\eta g_k$
محاسبه و سپس
$w_{t+1} \leftarrow \sum_{k=1}^K \frac{n_k}{n} w_{t+1}^k$
انجام شود.

در نتیجه، هر گره به صورت محلی یک گام گرادیان نزولی را روی مدل فعلی با استفاده از داده‌های محلی خود طی می‌کند و سپس سرور میانگین وزنی مدل‌های حاصل را محاسبه می‌کند. وقتی که الگوریتم به این صورت نوشته شود، می‌توانیم با تکرار به‌روزرسانی محلی
$w^k \leftarrow w^k-\eta \nabla F_k\left(w^k\right)$%
، چندین بار قبل از مرحله میانگین‌گیری، محاسبات بیشتری به هر گره اضافه کنیم. در نهایت این رویکرد جدید را
\lr{FederatedAveraging}
\lr{(FedAvg)}
می‌نامیم.

میزان محاسبات توسط سه پارامتر کلیدی کنترل می‌شود:
$C$%
، کسر گره‌هایی که در هر مرحله محاسبات انجام می‌دهند؛
$E$%
، تعداد مراحل آموزشی که هر گره در هر دور روی مجموعه داده محلی خود انجام می‌دهد؛ و
$B$%
، اندازه دسته محلی که برای به‌روزرسانی‌های هر گره استفاده می‌شود. در اینجا
$B = \infty$
را می‌نویسیم تا نشان دهیم که کل مجموعه داده محلی به عنوان یک دسته واحد در نظر گرفته می‌شود. بنابراین، به عنوان یک نمونه از این الگوریتم گسترده شده جدید، می‌توانیم
$B = \infty$
و
$E = 1$
را انتخاب کنیم که در این حالت دقیقاً با
\lr{FedSGD}
برابر خواهد شد. همچنین برای یک گره با
$n_k$
نمونه محلی، تعداد به‌روزرسانی‌های محلی در هر دور با
$u_k=E \frac{n_k}{B}$
نمایش داده می‌شود
\cite{mcmahan2017communication}.



\subsection{
بهینه‌سازی
\lr{\texttt{\fontspec{Times New Roman} FedProx}}
}
تست








\bigbreak\bigbreak\bigbreak\bigbreak\bigbreak\bigbreak
\bigbreak\bigbreak\bigbreak\bigbreak\bigbreak\bigbreak


\newcommand{\norm}[1]{\lVert#1\lVert}


یک سیستم زمان‌پیوسته در شکل~\ref{pic2-1} نشان داده شده است. این سیستم را به فرم استاندارد نیز می‌توان نمایش داد. در این فرم که در شکل~\ref{pic2-2} نشان داده شده است، سیگنال $w$ ورودی‌های خارجی سیستم نظیر ورودی مرجع\LTRfootnote{Reference Input}، نویز و اختلال را شامل می‌شود. $z$ سیگنالی است که قرار است کنترل شود و معمولاً خطای سیستم (اختلاف بین خروجی مطلوب و خروجی واقعی) است. $y$ ورودی کنترل‌کننده و $u$ نیز سیگنالی است که کنترل‌کننده آن را تولید می‌کند و به سیگنال کنترل معروف است. هم‌چنین در این فرم به دلیل این‌که سیستم $G$ دو ورودی و دو خروجی دارد، می‌توان آن را به چهار بخش به صورت 
\begin{equation*}
G=
\begin{bmatrix}
G_{11}&G_{12}\\G_{21}&G_{22}
\end{bmatrix} 
\end{equation*}
تقسیم کرد. در این صورت روابط
\begin{equation*}
\left\{\begin{array}{l}
z=G_{11}w+G_{12}u\\
y=G_{21}w+G_{22}u
\end{array}\right. 
\end{equation*}
بین ورودی‌ها و خروجی‌ها برقرار است.

\setlength{\unitlength}{1cm}
\begin{figure}[b]
\centering
\lr{
\begin{picture}(10.5,2.3)(0,0)
\put(0,1.5){\vector(1,0){1.35}}
\put(0.675,1.7){\makebox(0,0)[b]{$r(t)$}}
\put(1.2,1.7){\makebox(0,0){$ \scriptstyle + $}}
\put(1.5,1.5){\circle{0.3}}
\put(1.65,1.5){\vector(1,0){1.35}}
\put(2.325,1.7){\makebox(0,0)[b]{$e(t)$}}
\put(3,1){\framebox(1.5,1){$K(t) $}}
\put(4.5,1.5){\vector(1,0){1.5}}
\put(5.25,1.7){\makebox(0,0)[b]{$u(t)$ }}
\put(6,1){\framebox(1.5,1){$G(s)$}}
\put(7.5,1.5){\line(1,0){1.5}}
\put(9,1.5){\circle*{0.08}}
\put(9,1.5){\vector(1,0){1.5}}
\put(9.75,1.7){\makebox(0,0)[b]{$y(t)$}}
\put(9,1.5){\line(0,-1){1.5}}
\put(9,0){\line(-1,0){7.5}}
\put(1.5,0){\vector(0,1){1.35}}
\put(1.3,1.2){\makebox(0,0){$ \scriptstyle - $}}
\end{picture}
}
\caption{یک سیستم زمان‌پیوسته}
\label{pic2-1}
\end{figure} 

\setlength{\unitlength}{1cm}
\begin{figure}[b]
\centering
\lr{
\begin{picture}(5.4,4)(0,0)
\put(2,2.2){\framebox(1.4,1.4){$G$}}
\put(0,3.3){\vector(1,0){2}}
\put(1,3.5){\makebox(0,0)[b]{$w$}}
\put(3.4,3.3){\vector(1,0){2}}
\put(4.4,3.5){\makebox(0,0)[b]{$z$}}
\put(3.4,2.5){\line(1,0){1.5}}
\put(4.9,2.5){\line(0,-1){2}}
\put(5.1,1.5){\makebox(0,0)[l]{$y$}}
\put(4.9,0.5){\vector(-1,0){1.7}}
\put(2.2,0){\framebox(1,1){$K$}}
\put(2.2,0.5){\line(-1,0){1.7}}
\put(0.5,0.5){\line(0,1){2}}
\put(0.3,1.5){\makebox(0,0)[r]{$u$}}
\put(0.5,2.5){\vector(1,0){1.5}}
\end{picture}
}
\caption{یک سیستم زمان‌پیوسته در فرم استاندارد}
\label{pic2-2}
\end{figure} 


کنترل‌کننده بهینه $\mathcal{H}_2$، یک کنترل‌کننده علی و مناسب\LTRfootnote{Proper} است که سیستم را به‌طور داخلی پایدار کند و هم‌چنین به‌وسیله آن نرم $\mathcal{H}_2$ تابع تبدیل از  $z$ به $w$ ($T_{zw}$) مینیمم شود. به‌طور معادل می‌توان گفت کنترل‌کننده‌ای است که نرم دو پاسخ ضربه سیگنال  $z$ را مینیمم کند~\cite{paper_4}. در صورتی که سیستم متغیر با زمان باشد، تابع تبدیل مفهومی ندارد و از پاسخ ضربه باید استفاده کرد.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{کنترل‌کننده بهینه $\mathcal{H}_2$ برای سیستم‌های زمان‌پیوسته}
در این قسمت روش طراحی کنترل‌کننده بهینه $\mathcal{H}_2$ برای یک سیستم زمان‌پیوسته بیان می‌شود. بدین منظور ابتدا به تعریف نرم $\mathcal{H}_2$ برای سیستم‌های زمان‌پیوسته می‌پردازیم و پس از آن روش طراحی کنترل‌کننده را بیان می‌کنیم.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\subsection{تعریف نرم $\mathcal{H}_2$ برای سیستم‌های زمان‌پیوسته} 
برای یک سیستم خطی، تغییرناپذیر با زمان و پایدار $G$ که زمان‌پیوسته و تک ورودی-تک خروجی است، نرم $\mathcal{H}_2$ به صورت 
\begin{equation}
\norm{\hat{g}(s)}_{2}=\sqrt{\dfrac{1}{2\pi}\int_{-\infty}^{\infty}{{\vert \hat{g}(j\omega)\vert}^2}d\omega} 
\label{eq2-1}
\end{equation}
تعریف می‌شود. در این رابطه $\hat{g}(j\omega) $ پاسخ فرکانسی سیستم است. بر اساس خاصیت پارسوال\LTRfootnote{Parseval}،  نرم $\mathcal{H}_2$ یک سیستم پایدار، با نرم دو پاسخ ضربه آن برابر است. 
اگر 
$\hat{g}(s)$
تابع تبدیل یک سیستم زمان‌پیوسته پایدار و
$G\delta(t)$
پاسخ ضربه آن باشد، آن‌گاه رابطه
\begin{equation}
\norm{\hat{g}(s)}_{2}=\norm{G\delta(t)}_{2} = \sqrt{\int_{0}^{\infty}{{\vert G\delta(t)\vert}^2}d t} 
\label{eq2-2}
\end{equation}
برقرار است.

برای سیستم‌های چند ورودی-چند خروجی روابط کمی پیچیده‌تر می‌شوند. فرض کنید سیستم $G$، $m$ ورودی و $p$ خروجی داشته باشد. در این صورت ماتریس انتقال آن، $p$ سطر و $m$ ستون دارد. نرم $\mathcal{H}_2$ برای چنین سیستمی به صورت
\begin{equation*}
\norm{\hat{g}(s)}_{2}=\sqrt{\dfrac{1}{2\pi}\int_{-\infty}^{\infty}{trace\left[ \hat{g}^{*}(j\omega)\hat{g}(j\omega)\right] }d\theta} 
\end{equation*}
تعریف می‌شود. در این رابطه، $\hat{g}(s)$ ماتریس انتقال سیستم است. هم‌چنین طبق خاصیت پارسوال اگر سیستم پایدار باشد رابطه 
\begin{equation}
\norm{\hat{g}(s)}_{2}=\sum_{i=1}^{m}{\norm{G\delta(t)e_{i}}_{2}} 
\label{eq2-3}
\end{equation}
نیز برای آن برقرار است. در این رابطه $e_{i}$ها بردارهای پایه استاندارد در فضای $\mathbb{R}^{m}$ هستند. $\delta(t)e_{i}$ تابع ضربه‌ای است که به ورودی $i$ام اعمال شده و $G\delta(t)e_{i}$ خروجی مربوط به آن است.

در صورتی که سیستم پایدار باشد، می‌توان از فضای حالت سیستم نیز برای محاسبه نرم $\mathcal{H}_2$ استفاده کرد.  فرض کنید معادلات فضای حالت یک سیستم پایدار به صورت 
\begin{equation*}
\left\{\begin{array}{l}
\dot{x}=Ax +Bu\\
y =Cx+Du 
\end{array}\right. 
\end{equation*}
باشد که $x$ بردار حالت سیستم، $u$ بردار ورودی و $y$ بردار خروجی است. $A$ نیز یک ماتریس هرویتز\LTRfootnote{Hurwitz} است. هم‌چنین برای محدود بودن نرم $\mathcal{H}_2$ سیستم زمان‌پیوسته، $D$ باید صفر باشد. در این صورت برای محاسبه نرم $\mathcal{H}_2$ سیستم، می‌توان از روش زیر استفاده کرد \cite{book_1}: 
\begin{enumerate}
\item
حل معادله لیاپانوف زمان‌پیوسته\LTRfootnote{Continuous-time Lyapunov Equation} ($AL+LA^{T}+BB^{T}=0$) و یافتن ماتریس نامعلوم $L$.
\newline
باید دقت شود که در صورت هرویتز بودن ماتریس $A$، معادله لیاپانوف حل یکتا دارد.
\item
محاسبه نرم  $\mathcal{H}_2$از طریق رابطه $\norm{\hat{g}}_{2}=\sqrt{trace(CLC^{T})}$.
\cite{ref3}
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
