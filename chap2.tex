% Chapter 2
\chapter{مفاهیم پایه در یادگیری فدرال و نگاه کلی به پیشینه پژوهش چالش‌ها}

\section{مقدمه}
توزیع داده‌ها بین کاربران در یادگیری فدرال ممکن است با چالش‌ها و مشکلات گوناگونی روبرو شود. یکی از مشکلات اساسی، اختلافات و ناسازگاری‌هایی است که ممکن است در فرآیند آموزش میان کاربران یا دستگاه‌های مختلف پدید آید. اگر این چالش‌ها پیش از آغاز فرآیند مدل‌سازی به درستی شناسایی نشده و راه‌حل‌های مناسبی برای آن‌ها اتخاذ نشود، مدل نهایی احتمالاً با مشکلاتی همچون کاهش دقت و عملکرد روبرو خواهد شد. این مسئله یکی از بزرگترین موانع در مسیر یادگیری فدرال است و نیازمند دقت و استفاده از روش‌های خلاقانه برای حل آن است.

در این فصل، ابتدا به بیان ریاضی یادگیری فدرال پرداخته می‌شود که برای درک آن نیاز به آشنایی پایه با مفاهیم ریاضی در یادگیری ماشین و یادگیری عمیق است. سپس چالش‌های موجود در یادگیری فدرال بررسی شده و دیدگاه‌های مختلف مقالات علمی در مورد هر یک از این چالش‌ها به صورت کلی مرور می‌شود. در نهایت، به رویکردهای اصلی و اساسی برای حل این چالش‌ها اشاره خواهد شد.


\section{ریاضیات پایه در یادگیری فدرال}
برای تشریح ریاضیات پایه در یادگیری فدرال، ابتدا لازم است تا مفاهیم اساسی یادگیری ماشین و یادگیری عمیق را بررسی کنیم و رابطه‌های اصلی مرتبط با آن‌ها را بیان کنیم. پس از این مقدمه، با مرتبط کردن این اصول به یادگیری فدرال، می‌توانیم به طور دقیق ریاضیات اولیه در یادگیری فدرال را توضیح دهیم و نشان دهیم که چگونه این مفاهیم در این حوزه خاص به کار گرفته می‌شوند.

\subsection{مفاهیم پایه در یادگیری ماشین و یادگیری عمیق}
یادگیری ماشین شاخه‌ای از هوش مصنوعی است که به سیستم‌ها اجازه می‌دهد بدون نیاز به برنامه‌نویسی صریح، از داده‌ها بیاموزند و پیش‌بینی کنند. در یادگیری ماشین، الگوریتم‌ها با استفاده از داده‌های ورودی، مدل‌هایی می‌سازند که می‌توانند الگوها و روابط پیچیده را در داده‌ها تشخیص دهند. این فرآیند به کامپیوترها امکان می‌دهد تا با تجربه و مشاهده، بهبود پیدا کنند و وظایفی مانند تشخیص تصویر، پردازش زبان طبیعی و پیش‌بینی بازار را انجام دهند.

در حالی که یادگیری عمیق یک زیرمجموعه از یادگیری ماشین است که از شبکه‌های عصبی مصنوعی برای مدل‌سازی و یادگیری از داده‌ها استفاده می‌کند. این روش‌ها از لایه‌های متعدد برای استخراج ویژگی‌ها و یادگیری الگوها در داده‌های پیچیده بهره می‌برند. شبکه‌های عصبی عمیق، که شامل چندین لایه مخفی هستند، قادر به یادگیری ویژگی‌های سطح بالا از داده‌های ورودی می‌باشند. این لایه‌ها به ترتیب اطلاعات را پردازش کرده و به یکدیگر منتقل می‌کنند تا خروجی نهایی تولید شود.

یادگیری عمیق برای تنظیم وزن‌های شبکه عصبی از الگوریتم‌های بهینه‌سازی بهره می‌برد. یکی از این الگوریتم‌ها، گرادیان نزولی%
\LTRfootnote{Gradient Descent}
است که با تعیین شیب تابع هزینه%
\LTRfootnote{Loss Function}%
، وزن‌ها را به‌طور مکرر به‌روزرسانی می‌کند تا به کمترین مقدار ممکن برای این تابع برسد. الگوریتم انتشار به عقب%
\LTRfootnote{Backpropagation}
یکی از مهم‌ترین روش‌ها در این زمینه است که از گرادیان نزولی برای بهینه‌سازی وزن‌ها استفاده می‌کند. در این فرآیند، ابتدا خطای خروجی شبکه محاسبه می‌شود و سپس این خطا به‌صورت معکوس از لایه خروجی به سمت لایه‌های ورودی منتقل می‌شود تا وزن‌ها تنظیم شوند و شبکه به دقت مطلوب دست یابد.


\subsection{فرمول‌های پایه در یادگیری عمیق}
\begin{itemize}
\item تابع هزینه و انتشار به عقب

تابع هزینه یا تابع خطا معیاری است که اختلاف بین خروجی پیش‌بینی شده و مقدار واقعی را اندازه‌گیری می‌کند. یکی از توابع هزینه رایج، میانگین مربعات خطا%
\LTRfootnote{Mean Squared Error}
\lr{(MSE)}
است:
\begin{equation}
	J(\theta) = \frac{1}{m} \sum_{i=1}^{m} (y_i - \hat{y}_i)^2
\end{equation}
که در آن
$y_i$
مقدار واقعی،
$\hat{y}_i$
مقدار پیش‌بینی شده و
$m$
تعداد نمونه‌ها است. الگوریتم انتشار به عقب از این تابع هزینه استفاده می‌کند تا وزن‌ها را به‌روزرسانی کند. این فرآیند شامل محاسبه گرادیان‌ها و به‌روزرسانی وزن‌ها در جهت کاهش خطا است.


\item بهینه‌سازی با گرادیان نزولی

بهینه‌سازی با گرادیان نزولی یکی از رایج‌ترین روش‌ها برای به‌روزرسانی وزن‌های شبکه عصبی است. رابطه به‌روزرسانی وزن‌ها به صورت زیر است:
\begin{equation}
	\theta_{j} \leftarrow \theta_{j} - \alpha \frac{\partial J(\theta)}{\partial \theta_{j}}
\end{equation}
که در آن
$\theta_{j}$
وزن،
$\alpha$
نرخ یادگیری و
$\frac{\partial J(\theta)}{\partial \theta_{j}}$
مشتق جزئی تابع هزینه نسبت به وزن
$\theta_{j}$
است. این فرآیند تکرار می‌شود تا تابع هزینه به حداقل مقدار خود برسد.
\end{itemize}


\subsection{ارتباط مفاهیم یادگیری عمیق با یادگیری فدرال}
یادگیری فدرال از مفاهیم پایه‌ای یادگیری عمیق و شبکه‌های عصبی بهره می‌برد، اما با ساختاری توزیع‌شده که در آن داده‌ها بین چندین دستگاه تقسیم شده‌اند. در یادگیری فدرال، مدل‌های یادگیری عمیق به‌صورت محلی بر روی دستگاه‌های کاربران آموزش داده می‌شوند و تنها به‌روزرسانی‌های مدل به سرور مرکزی ارسال می‌شود. این روش، علاوه بر حفظ حریم خصوصی داده‌ها، امکان استفاده از داده‌های گسترده و متنوع را فراهم می‌کند. الگوریتم‌های بهینه‌سازی مانند گرادیان نزولی و انتشار به عقب به‌طور محلی اجرا می‌شوند و به‌روزرسانی‌ها به‌صورت تجمیعی برای بهبود مدل کلی استفاده می‌شوند، که یادگیری فدرال را به یک رویکرد قدرتمند برای مدل‌سازی در محیط‌های توزیع‌شده تبدیل می‌کند.



\subsection{بیان ریاضی یادگیری فدرال}
برای بررسی مباحث ریاضی پایه در یادگیری فدرال، ابتدا باید مسئله بهینه‌سازی مرکزی که در این زمینه مطرح می‌شود، به‌طور دقیق تعریف گردد. در یادگیری فدرال، هدف اصلی یافتن مجموعه‌ای از پارامترهای مدل است که عملکرد کلی مدل را بر روی داده‌های توزیع‌شده بین تعداد زیادی دستگاه بهینه کند. هر دستگاه دارای داده‌های محلی است و یک تابع هزینه محلی بر اساس این داده‌ها برای آن دستگاه تعریف می‌شود. مسئله بهینه‌سازی کلی در یادگیری فدرال به دنبال کمینه کردن مجموع وزنی این توابع هزینه محلی است تا یک مدل جامع و یکپارچه حاصل شود.

یک طرح به‌روزرسانی همزمان در نظر گرفته می‌شود که به صورت دوره‌های ارتباطی انجام می‌شود. در این سیستم، یک مجموعه ثابت از
$K$
مشتری وجود دارد که هر کدام دارای یک مجموعه داده محلی ثابت هستند. در ابتدای هر دوره، یک زیرمجموعه تصادفی شامل
$C$
مشتری‌ انتخاب می‌شود و سرور وضعیت فعلی پارامترهای مدل جهانی را به هر یک از این مشتری‌ها ارسال می‌کند. هر مشتری انتخاب ‌شده سپس بر اساس وضعیت جهانی و مجموعه داده محلی خود محاسبات محلی را انجام می‌دهد و یک به‌روزرسانی به سرور ارسال می‌کند. سپس سرور این به‌روزرسانی‌ها را برروی وضعیت جهانی خود اعمال می‌کند و این فرآیند تکرار می‌شود
\cite{mcmahan2017communication}.

در حالی که تمرکز بر اهداف شبکه عصبی غیرمحدب%
\LTRfootnote{non-Convex}
است، الگوریتم مورد بررسی برای هر هدف جمع-متناهی%
\LTRfootnote{Finite-Sum}
به صورت زیر قابل اعمال است.
\begin{equation}
	\min _{w \in \mathbb{R}^d} f(w) \quad \text { where } \quad f(w) \stackrel{\text { def }}{=} \frac{1}{n} \sum_{i=1}^n f_i(w)
	\label{eq_base}
\end{equation}
برای یک مسئله یادگیری ماشین، معمولاً
$f_i(w)=\ell\left(x_i, y_i ; w\right)$
در نظر گرفته می‌شود، به این معنی که این تابع نشان‌دهنده‌ی خطای پیش‌بینی بر روی نمونه
$(x_i, y_i)$
با استفاده از پارامترهای مدل
$w$
است. فرض می‌کنیم که داده‌ها بین
$K$
مشتری تقسیم شده‌اند، که در آن
$\mathcal{P}_k$
مجموعه‌ای از نقاط داده مربوط به مشتری
$k$
است و
$n_k=\left|\mathcal{P}_k\right|$
تعداد این نقاط داده را نشان می‌دهد. بنابراین، با توجه به این مورد می‌توان رابطه
\eqref{eq_base}
را به صورت زیر بازنویسی نمود:
\begin{equation}
	f(w)=\sum_{k=1}^K \frac{n_k}{n} F_k(w) \quad \text { where } \quad F_k(w)=\frac{1}{n_k} \sum_{i \in \mathcal{P}_k} f_i(w)
\end{equation}

اگر مجموعه
$\mathcal{P}_k$
با توزیع یکنواخت%
\LTRfootnote{Uniform Distribution}
تصادفی از مثال‌های آموزشی بین مشتری‌ها تشکیل شده باشد، در آن صورت
$\mathbb{E}_{\mathcal{P}_k}\left[F_k(w)\right]=f(w)$ 
خواهد بود، که در اینجا امید ریاضی بر روی مجموعه مثال‌های اختصاص داده شده به یک مشتری ثابت گرفته می‌شود. این همان فرض
استقلال و توزیع یکنواخت داده‌ها%
\LTRfootnote{Independent and Identically Distributed}
\lr{(IID)}
است که عموماً توسط الگوریتم‌های بهینه‌سازی توزیع‌شده استفاده می‌شود، در اینجا حالتی که فرض مذکور برقرار نیست (یعنی
$F_k$
می‌تواند تقریباً به هر میزانی از
$f$
فاصله داشته باشد) به عنوان حالت
غیرمستقل و غیریکنواخت
\lr{(non-IID)}
شناخته می‌شود
\cite{mcmahan2017communication}.



\section{چالش‌های موجود در یادگیری فدرال و نگاه کلی مقالات به آن‌ها}
با وجود مزایای فراوان در مقایسه با روش‌های سنتی یادگیری ماشین، یادگیری فدرال به دلیل ساختار شبکه‌ای خود با چالش‌های متعددی مواجه است. در ادامه به بررسی چالش‌های اصلی یادگیری فدرال و دیدگاه کلی مقالات در مورد آن‌ها خواهیم پرداخت.


\subsection{تبادل داده}
تبادل داده بین سرور و کاربران به دلیل مشکلات پهنای باند و ارتباطات شبکه‌ای اصولا کار پر هزینه‌ای می‌باشد. یکی از دلایل اصلی پرهزینه بودن این ارتباطات، حجم بالای داده‌هایی است که باید بین دستگاه‌های کاربری و سرور منتقل شوند.
معمولاً مشکلات ارتباطی به انتقال‌های بسیار زیاد به‌روزرسانی‌های مدل بین گره‌های محاسباتی نسبت داده می‌شود. با افزایش تعداد پارامترها در مدل‌های پیشرفته، اندازه این مدل‌ها نیز به طور متناسب بزرگ می‌شود
\cite{wang2018atomo}.

از سوی دیگر، تعداد زیادی از دستگاه‌های کاربران نهایی در فرآیند آموزش مدل‌ها مشارکت دارند که این امر می‌تواند هزینه‌های ارتباطی را به طور قابل توجهی افزایش دهد. همچنین، به دلیل مشکلات ارتباطی، در بسیاری از مواقع همه دستگاه‌ها در هر چرخه از فرآیند آموزش شرکت نمی‌کنند که این مسئله نیز باعث افزایش هزینه‌ها و پیچیدگی‌های مرتبط با انتقال داده‌ها می‌شود.


استفاده از فشرده‌سازی داده‌ها می‌تواند هزینه‌های ارتباطی را به میزان قابل توجهی کاهش دهد. برای مدیریت هزینه‌های بالای ارتباطات در فرآیند یادگیری فدرال، روش‌هایی مورد بررسی قرار گرفته‌اند که بر فشرده‌سازی داده‌های ارسالی از دستگاه‌های نهایی به سرور مرکزی تمرکز دارند. این تکنیک‌ها با کاهش حجم اطلاعات ارسالی، به کاهش هزینه‌های ارتباطی کمک می‌کنند
\cite{konevcny2016federated}.

روشی به نام
\lr{PCFL}%
\LTRfootnote{Privacy Communication efficient Federated Learning}
وجود دارد که از نظر ارتباطی بسیار کارآمد است و شامل سه عنصر اصلی می‌باشد. این عناصر شامل فشرده‌سازی دوطرفه، فشرده‌سازی مکانی وزن‌ها و یک پروتکل پیشرفته برای حفظ حریم خصوصی داده‌ها هستند. فشرده‌سازی دوطرفه، داده‌ها را در دو مرحله، هم قبل از ارسال از دستگاه‌های نهایی به سرور و هم هنگام ارسال نتایج به‌روزرسانی‌شده از سرور به دستگاه‌ها، فشرده می‌کند تا حجم داده‌های انتقالی کاهش یابد. فشرده‌سازی مکانی وزن‌ها نیز با فشرده کردن وزن‌های مدل، حجم انتقال را کاهش داده و کارایی ارتباطات را بهبود می‌بخشد. پروتکل حفظ حریم خصوصی داده‌ها نیز امنیت اطلاعات کاربران را در طول فرآیند یادگیری فدرال تضمین می‌کند. این سه عنصر با همکاری هم، موجب کاهش هزینه‌های ارتباطی و بهبود کارایی در روش
\lr{PCFL}
می‌شوند
\cite{fang2021privacy}.



\subsection{
	ناهمگنی‌های سیستمی%
\LTRfootnote{Systems Heterogeneity}
}
در دنیای یادگیری فدرال، دستگاه‌ها از نظر حافظه، توان محاسباتی و ارتباطات بسیار با یکدیگر متفاوت هستند. این تفاوت‌ها ممکن است از اختلافاتی مانند تفاوت در پردازنده، نوع حافظه، نوع اتصال شبکه و نیاز به انرژی ناشی شود. محدودیت‌های موجود در شبکه و سیستمی می‌توانند باعث ایجاد وضعیت‌هایی شوند که برخی از دستگاه‌ها در یک زمان معین در دسترس نباشند. برای مثال، اگر تعداد زیادی دستگاه همزمان درخواست ارسال داشته باشند، ممکن است برخی از آن‌ها به دلیل پهنای باند محدود یا محدودیت‌های سخت‌افزاری، قادر به ارسال درخواست نشوند. همچنین، ممکن است یک دستگاه فعال، به دلیل مشکلاتی مانند اختلالات در شبکه یا مصرف اضافی انرژی، از فرآیند یادگیری خارج شود.

این تفاوت‌های سیستمی، یکی از چالش‌های یادگیری فدرال محسوب می‌شوند و می‌توانند باعث افزایش تأخیر و ایجاد اشکالات در سیستم شوند. بنابراین، برای رفع این مشکلات، روش‌های یادگیری فدرال باید توانایی پیش‌بینی دقیق تعداد دستگاه‌هایی که در هر فرآیند شرکت می‌کنند را داشته باشند. همچنین، باید بتوانند در برابر دستگاه‌هایی که در حین عملیات دچار مشکل شده و از دسترس خارج می‌شوند، مقاومتی مناسب داشته باشند
\cite{li2020federated}.


برای مقابله با ناهمگنی سیستمی، روشی تحت عنوان تعادل در به‌روزرسانی مدل مطرح شده است. در این روش، وزن‌دهی به نمونه‌ها بر اساس میزان نیاز به آموزش در هر دستگاه صورت می‌گیرد. این کار باعث می‌شود که دستگاه‌های با حجم داده کمتر، وزن بیشتری در به‌روزرسانی مدل داشته باشند
\cite{konevcny2015federated}.
در رویکرد دیگری به نام یادگیری فعال، دستگاه‌هایی که داده‌های خود را به سرور ارسال می‌کنند، فعالیت خود را به نحوی تنظیم می‌کنند که مدل از داده‌های مهم‌تر و کمتر دیده شده بیشتر یاد می‌گیرد. این روش می‌تواند به تعادل در آموزش مدل کمک کند و از ناهمگنی سیستمی جلوگیری کند
\cite{konevcny2016federated}.


\subsection{
	ناهمگنی‌های آماری%
\LTRfootnote{Statistical Heterogeneity}
}
روش‌های مختلفی برای تولید و جمع‌آوری داده‌ها بین دستگاه‌ها وجود دارد. این داده‌ها معمولاً به صورت مستقل از هم تولید نمی‌شوند و بین آن‌ها ارتباطات و پیوندهایی وجود دارد. چنین الگویی از تولید داده با فرضیات استقلال و توزیع یکنواخت داده‌ها
\lr{(IID)}
در مسائل بهینه‌سازی در تضاد است، که منجر به پیچیدگی‌هایی در فرآیند مدل‌سازی، تحلیل نظری و ارزیابی عملکرد می‌شود. بنابراین، با وجود هدف نهایی که یادگیری یک مدل جامع و یکپارچه است، روش‌های جایگزین مانند یادگیری چندوظیفه‌ای%
\LTRfootnote{Multi-Tasking}
و فرایادگیری%
\LTRfootnote{Meta Learning}
به عنوان راه‌حل‌های ممکن مطرح شده‌اند
\cite{li2020federated}.


یک روش برای حل مشکل ناهمگنی آماری در یادگیری فدرال استفاده از رویکرد ترکیبی یا ترکیب روش‌های یادگیری محلی است. در این رویکرد، به جای استفاده از یک الگوریتم یادگیری مشترک برای تمام دستگاه‌ها، از چندین الگوریتم یادگیری محلی با تنوع مدل‌ها و تنظیمات مختلف استفاده می‌شود. سپس، اطلاعات مدل‌های محلی روی سرور یا گره مرکزی جمع‌آوری می‌شود و با استفاده از ترکیب این اطلاعات، یک مدل یادگیری مشترک به‌روزرسانی خواهد شد
\cite{konevcny2015federated}.



\subsection{حریم شخصی}
اگرچه حفظ حریم شخصی یک مزیت مهم در یادگیری فدرال به شمار می‌رود، اما در صورت عدم کنترل مناسب می‌تواند به یک چالش تبدیل شود. یکی از چالش‌های اساسی در این زمینه، نگهداری حریم خصوصی است که به دلیل قرار گرفتن داده‌های حساس و شخصی در اختیار بخش‌های مختلف شبکه، اهمیت بیشتری پیدا می‌کند. در این روش، دستگاه‌های محلی داده‌های کاربران را جمع‌آوری و به سرور ارسال می‌کنند تا مدل‌های یادگیری مشترک به‌روزرسانی شوند. این ارتباطات می‌توانند شامل اطلاعات حساسی باشند که امکان شناسایی افراد یا فرآیندهای حیاتی آن‌ها را فراهم می‌کنند.

یکی از مشکلات کلیدی اینجاست که حتی با استفاده از روش‌های رمزنگاری و امنیتی، ممکن است اطلاعات خاصی همچنان به سرور ارسال شوند که می‌تواند حریم خصوصی را نقض کند. به‌ویژه، اگر داده‌های حساس مانند اطلاعات هویتی به صورت رمزگذاری نشده انتقال یابند، امنیت حریم خصوصی کاربران به خطر می‌افتد.


روش حفظ حریم خصوصی تفاضلی%
\LTRfootnote{Differential Privacy}
با افزودن نویز به نتایج محاسبات یا به داده‌های ورودی، اطمینان حاصل می‌کند که حضور یا عدم حضور یک نمونه داده خاص در مجموعه داده‌ها، تأثیر قابل توجهی بر خروجی محاسبات نداشته باشد. این روش به ویژه برای حفظ حریم خصوصی در یادگیری فدرال مفید است زیرا از افشای اطلاعات حساس از طریق پارامترهای مدل جلوگیری می‌کند
\cite{hasan2023security}.

رویکرد رمزنگاری هم‌شکل%
\LTRfootnote{Homomorphic Encryption}
امکان محاسبه روی داده‌های رمزنگاری شده را بدون نیاز به رمزگشایی آن‌ها فراهم می‌کند. این تکنیک به ویژه در یادگیری فدرال برای حفظ حریم خصوصی داده‌ها در حین انجام محاسبات مفید است زیرا نیاز به تغییر ماهیت داده نبوده و چون جابجایی در یادگیری فدرال بسیار زیاد رخ می‌دهد، این روش بسیار کارا خواهد بود
\cite{yin2021comprehensive}.



\section{رویکردهای کلی و پایه‌ای در حل چالش‌ها}
روش‌های بهینه‌سازی توزیع‌شده معمولاً برای حل مسائل بهینه‌سازی در سیستم‌هایی با شبکه‌های محاسباتی بزرگ و توزیع‌شده استفاده می‌شوند. این روش‌ها بر مبنای تقسیم مسئله بهینه‌سازی به زیرمسائل کوچک‌تر و حل آن‌ها در گره‌های مختلف شبکه استوارند. در این روش‌ها، اغلب فرض می‌شود که داده‌ها به صورت همگن و یکپارچه در سراسر شبکه توزیع شده‌اند و گره‌ها می‌توانند به راحتی با یکدیگر ارتباط برقرار کنند.

این فرضیات در یادگیری فدرال به ندرت برقرار است، زیرا در یادگیری فدرال داده‌ها به صورت محلی و ناهمگن در دستگاه‌های مختلف قرار دارند و ارتباطات بین دستگاه‌ها ممکن است محدود و نامنظم باشد. بنابراین روش‌ها و رویکردهای لازم جهت حل این چالش‌ها متفاوت از مسائل بهینه‌سازی توزیع شده هستند. در این مرحله، تلاش می‌شود دو رویکرد پایه‌ای برای مسائل یادگیری فدرال معرفی شود.

\subsection{به‌روزرسانی محلی و میانگین‌گیری در سرور}
یکی از روش‌های اصلی و پرکاربرد در یادگیری فدرال روش میانگین‌گیری فدرال%
\LTRfootnote{Federated Averaging}
\lr{(FedAvg)}
است که توسط محققان گوگل در سال 2017 معرفی شد
\cite{mcmahan2017communication}.
این الگوریتم به منظور بهینه‌سازی مدل‌های یادگیری ماشین در یک محیط توزیع‌شده طراحی شده است. در این روش داده‌ها به صورت محلی در دستگاه‌های کاربران باقی می‌مانند و تنها به‌روزرسانی‌های مدل به اشتراک گذاشته می‌شوند. رویکرد اصلی
\lr{FedAvg}
بر مبنای ترکیب به‌روزرسانی‌های محلی از دستگاه‌های مختلف به یک مدل جهانی استوار است.

یکی از مزایای اصلی
\lr{FedAvg}
این است که به طور موثری با چالش ناهمگنی داده‌ها مقابله می‌کند. در یادگیری فدرال، داده‌های موجود در دستگاه‌های مختلف ممکن است توزیع‌های متفاوتی داشته باشند. این ناهمگنی می‌تواند به دلیل تفاوت در رفتار کاربران یا حتی محیط‌های مختلف جمع‌آوری داده باشد. میانگین‌گیری وزنی در
\lr{FedAvg}
به مدل کمک می‌کند تا به‌روزرسانی‌های مختلف را به گونه‌ای ترکیب کند که این ناهمگنی‌ها را در نظر بگیرد. به عبارت دیگر، اگر یک دستگاه داده‌های بیشتری داشته باشد، تأثیر بیشتری بر مدل نهایی خواهد داشت. این رویکرد باعث می‌شود که مدل فدرال به تعادل بهتری در یادگیری از داده‌های ناهمگن برسد و کارایی بالاتری داشته باشد. این ویژگی به ویژه در کاربردهایی مانند فروشگاه برنامه‌های کاربردی که کاربران متنوع و داده‌های متفاوتی دارند، بسیار سودمند است و می‌تواند به بهبود عملکرد مدل در شرایط واقعی کمک شایانی کند.

علاوه بر این،
\lr{FedAvg}
به کاهش نیاز به ارتباطات مکرر بین دستگاه‌ها و سرور مرکزی کمک می‌کند. در بسیاری از روش‌های بهینه‌سازی توزیع‌شده، نیاز است که دستگاه‌ها به طور مکرر با سرور مرکزی ارتباط برقرار کنند تا به‌روزرسانی‌های خود را ارسال کنند. اما در
\lr{FedAvg}
دستگاه‌ها می‌توانند چندین مرحله از بهینه‌سازی را به صورت محلی انجام دهند و سپس تنها به‌روزرسانی نهایی را ارسال کنند. این کاهش در نیاز به ارتباطات نه تنها باعث کاهش پهنای باند مورد نیاز می‌شود، بلکه به حفظ حریم خصوصی کاربران نیز کمک می‌کند، زیرا داده‌ها هرگز از دستگاه‌های محلی خارج نمی‌شوند. بررسی‌ها نشان داده‌اند که متناسب با اندازه داده‌ها پس از رسیدن به تعداد معینی از گره‌ها، اضافه کردن گره‌های بیشتر تأثیری در کاهش هزینه‌های ارتباطی نخواهد داشت. در چنین شرایطی، تمرکز بر افزایش توان محاسباتی محلی یا تعداد مراحل آموزش محلی می‌تواند موجب تسریع فرایند آموزش شود
\cite{mcmahan2017communication}.

موفقیت‌های اخیر در کاربردهای یادگیری عمیق تقریباً به‌طور انحصاری به استفاده از انواع الگوریتم نزول گرادیان تصادفی%
\LTRfootnote{Stochastic Gradient Descent}
\lr{(SGD)}
برای بهینه‌سازی متکی بوده‌اند. در واقع، بسیاری از پیشرفت‌ها به تنظیم مدل و بهینه‌سازی تابع خطا با روش‌های ساده گرادیان مربوط می‌شود. بنابراین، منطقی است که الگوریتم‌های بهینه‌سازی فدرال با شروع از
\lr{SGD}
طراحی و توسعه یابند
\cite{mcmahan2017communication}.

الگوریتم
\lr{SGD}
می‌تواند به سادگی در بهینه‌سازی فدرال استفاده شود، به این صورت که در هر دور ارتباط، گرادیان‌ها بر اساس داده‌های یک مشتری تصادفی انتخاب شده، محاسبه ‌شوند. این رویکرد از نظر محاسباتی کارآمد است، اما نیازمند تعداد بسیار زیادی از دورهای آموزش برای تولید مدل‌های خوب است.
برای مثال حتی با استفاده از رویکرد پیشرفته‌ای مانند نرمال‌سازی دسته‌ای%
\LTRfootnote{Batch Normalization}%
، برای آموزش مجموعه‌داده معروف
\lr{MNIST}
(دیتاستی جهت دسته‌بندی اعداد دستنویس بین صفر تا نه)
با دسته‌های کوچکی به اندازه 60 به 50000 دور آموزش جهت رسیدن به مدل مطلوب نیاز می‌باشد
\cite{ioffe2015batch}.

در تنظیمات فدرال، مشارکت تعداد زیادی از مشتریان هزینه چندانی در زمان واقعی ندارد زیرا همه کاربران می‌توانند به صورت همزمان به آموزش مدل محلی بپردازند. بنابراین، برای خط مبنا از
\lr{SGD}
همزمان با دسته‌های بزرگ استفاده می‌شود. برای اعمال این رویکرد در تنظیمات فدرال، در هر دور یک زیرمجموعه‌ای از مشتریان با ضریب کنترلی 
$C$
انتخاب می‌شوند و گرادیان خطا روی تمام داده‌های نگهداری شده توسط این مشتریان محاسبه می‌گردد. بنابراین،
$C$
اندازه دسته کلی را کنترل می‌کند، به‌طوری که
$C = 1$
معادل با نزول گرادیان یک دسته کامل است. این الگوریتم خط مبنا
\lr{FederatedSGD}
یا
\lr{FedSGD}
نامیده می‌شود
\cite{mcmahan2017communication}.


یک پیاده‌سازی معمول از
\lr{FedSGD}
با
$C = 1$
و نرخ یادگیری ثابت
$\eta$
به این صورت است که هر گره
$k$%
، گرادیان
$g_k=\nabla F_k\left(w_t\right)$
که میانگین گرادیان روی داده‌های محلی در مدل فعلی
$w_t$
است را محاسبه می‌کند و سرور مرکزی این گرادیان‌ها را جمع‌آوری کرده و به‌روزرسانی
$w_{t+1} \leftarrow w_t-\eta \sum_{k=1}^K \frac{n_k}{n} g_k$
را انجام می‌دهد، در حالی که
$\sum_{k=1}^K \frac{n_k}{n} g_k=\nabla f\left(w_t\right)$
خواهد بود. یک به‌روزرسانی معادل به این صورت است که برای هر گره عبارت
$\forall k, w_{t+1}^k \leftarrow w_t-\eta g_k$
محاسبه و سپس
$w_{t+1} \leftarrow \sum_{k=1}^K \frac{n_k}{n} w_{t+1}^k$
انجام شود.

در نتیجه، هر گره به صورت محلی یک گام گرادیان نزولی را روی مدل فعلی با استفاده از داده‌های محلی خود انجام داده و سپس سرور میانگین وزنی مدل‌های به‌دست‌آمده را محاسبه می‌کند. با نوشتن الگوریتم به این صورت، امکان تکرار به‌روزرسانی محلی
$w^k \leftarrow w^k-\eta \nabla F_k\left(w^k\right)$%
، چندین بار پیش از مرحله میانگین‌گیری فراهم شده و باعث افزایش محاسبات در هر گره خواهد شد. الگوریتم
\lr{FederatedAveraging}
\lr{(FedAvg)}
به این صورت به وجود آمد
\cite{mcmahan2017communication}.
جهت درک بهتر این ساختار می‌توانید شکل
\ref{federated_learning}
را مشاهده کرده و در گام سوم شکل میانگین وزنی مدل‌ها را در نظر بگیرید.


در این روش میزان محاسبات توسط سه پارامتر کلیدی کنترل می‌شود:
$C$%
، زیرمجموعه‌ای از تعداد گره‌هایی که در هر مرحله محاسبات انجام می‌دهند؛
$E$%
، تعداد مراحل آموزشی که هر گره در هر دور روی مجموعه داده محلی خود انجام می‌دهد؛ و
$B$%
، اندازه دسته محلی که برای به‌روزرسانی‌های هر گره استفاده می‌شود. در اینجا
$B = \infty$
انتخاب می‌شود تا نشان دهد که کل مجموعه داده محلی به عنوان یک دسته واحد در نظر گرفته می‌شود. بنابراین، به عنوان یک نمونه از این الگوریتم گسترده شده جدید، انتخاب
$B = \infty$
و
$E = 1$
باعث می‌شود که این روش دقیقاً مانند
\lr{FedSGD}
عمل کند. همچنین برای یک گره با
$n_k$
نمونه محلی، تعداد به‌روزرسانی‌های محلی در هر دور با
$u_k=E \frac{n_k}{B}$
نمایش داده می‌شود
\cite{mcmahan2017communication}.
%شبه کد کامل این روش در الگوریتم
%\ref{algo_FedAvg}
%ارائه شده است. همچنین در جدول
%\ref{tabel_notation_FedAvg}
%تمام نمادهای مربوط به این الگوریتم بیان شده است. 
شبه کد کامل این روش در الگوریتم
\ref{algo_FedAvg}
ارائه شده است. علاوه بر این، تمامی نمادهای مورد استفاده در این الگوریتم در جدول
\ref{tabel_FedAvgNotations}
توضیح داده شده است. هدف از این جدول، فراهم کردن درکی جامع از نحوه عملکرد و پیاده‌سازی الگوریتم می‌باشد.


\begin{LTR}
\SetAlgoNlRelativeSize{-1}
\begin{algorithm}[t]
	\begin{RTL}
		\caption{%
میانگین‌گیری فدرال
			\lr{(FedAvg)}
			\cite{mcmahan2017communication}
		}
		\label{algo_FedAvg}
	\end{RTL}
	
	\begin{latin}
		initialize $w_0$\;
		\For{each round $t = 1, 2, \ldots, T$}{
			$m \gets \max(C \cdot K, 1)$\;
			$S_t \gets$ (random set of $m$ clients)\;
			\For{each client $k \in S_t$
				\textbf{in parallel}}{
				$w_{t+1}^k \gets \texttt{ClientUpdate}(k, w_t)$\;
			}
			$w_{t+1} \leftarrow \sum_{k=1}^K \frac{n_k}{n} w_{t+1}^k$\;
		}
		\SetKwFunction{ClientUpdate}{ClientUpdate}
		\SetKwProg{Fn}{Function}{:
		\quad // {\mdseries \textit{Run on client} $k$}
		}{end}
		\Fn{\ClientUpdate{$k, w$}}{
			$\mathcal{B} \leftarrow$ (split $\mathcal{P}_k$ into batches of size $B$)\;
			\For{each local epoch \space $i$ \space from $1$ to $E$}{
				\For{batch $b \in \mathcal{B}$}{
					$w \gets w - \eta \nabla \ell(w$%
					\texttt{\char`\~}%
					$b)$\;
				}
			}
			\KwRet $w$ to server\;
		}
	\end{latin}
\end{algorithm}
\end{LTR}


\begin{table}[h]
	\centering
	\caption{نمادهای الگوریتم
		\lr{FedAvg}
	}
	\label{tabel_FedAvgNotations}
	\begin{tabular}{cr}
		\hline
		متغیر & توضیحات \\
		\hline
		$w$ & وزن‌های شبکه‌عصبی \\
		$T$ & تعداد گام‌ها \\
		$K$ & تعداد مشتریان \\
		$C$ & ضریب کنترلی برای زیرمجموعه‌ای از مشتریان \\
		$n$ & تعداد داده‌های آموزشی \\
		$\mathcal{P}_k$ & مجموعه داده‌های متعلق به مشتری $k$ \\
		$B$ & اندازه دسته محلی \\
		$E$ & تعداد مراحل آموزش محلی \\
		$\eta$ & نرخ یادگیری \\
		\hline
	\end{tabular}
\end{table}


\subsection{
بهینه‌سازی
\lr{\texttt{\fontspec{Times New Roman} FedProx}}
}
روش
\lr{FedProx}
به بررسی چالش‌های یادگیری فدرال در بسترهای ناهمگن می‌پردازد. این روش با ایجاد تغییرات جزئی در روش موجود
\lr{FedAvg}%
، به بهبود پایداری و دقت در شبکه‌های ناهمگن کمک می‌کند. این تغییرات شامل اضافه کردن یک عبارت نزدیک مبدا%
\LTRfootnote{Proximal Term}
به تابع هدف است که به صورت اصولی به سرور کمک می‌کند تا ناهمگنی را مدیریت کند
\cite{li2020federatedheteroneneous}.

رابطه هدف
\lr{FedProx}
به صورت زیر تعریف می‌شود:
\begin{equation}
\min_{w} f(w) = \min_{w} \sum_{k=1}^{K} \frac{n_k}{n} \left( F_k(w) + \frac{\mu}{2} \|w_t - w_t^k\|^2 \right)
\label{eq_FedProx}
\end{equation}

در رابطه
\eqref{eq_FedProx}
بخش
$\frac{\mu}{2} \|w_t - w_t^k\|^2$%
، همان عبارت نزدیک مبدا است که به تابع هدف اضافه شده است. همچنین
$\mu$%
، یک پارامتر تنظیم برای این عبارت به حساب می‌آید و در نهایت
$w_t^k$
وزن‌های مدل محلی دستگاه
$k$
در تکرار
$t$
است.

حال با توجه به رابطه
\eqref{eq_FedProx}%
، به‌روزرسانی وزن‌ها به شکل زیر تغییر پیدا خواهد کرد و بخش
$\mu (w_t - w_t^k)$%
، گرادیان عبارت نزدیک مبدا است.
\begin{equation}
w_{t+1} = w_t - \eta (\nabla F_k(w_t) + \mu (w_t - w_t^k))
\end{equation}

بنابراین، به‌روزرسانی‌های محلی در هر گام با به‌روزرسانی سراسری مرحله قبل مرتبط هستند. عبارت نزدیک مبدا به عنوان یک مکانیزم منظم‌کننده%
\LTRfootnote{Regularization}
عمل می‌کند که تفاوت‌های بین وزن‌های جهانی
$w$
و وزن‌های محلی
$w_t^k$
را کاهش می‌دهد. این ترم به کاهش تاثیرات منفی ناهمگنی سیستم‌ها و داده‌ها کمک می‌کند و باعث پایداری بیشتر در فرآیند همگرایی می‌شود
\cite{li2020federatedheteroneneous}.

